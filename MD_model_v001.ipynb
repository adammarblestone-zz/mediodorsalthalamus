{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammarblestone/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_batches = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a feedforward NN representing the sensory-motor system\n",
    "\n",
    "input_vis = tf.placeholder(shape=[batch_size, 2], dtype=tf.float32, name = 'input_vis')\n",
    "input_aud = tf.placeholder(shape=[batch_size, 2], dtype=tf.float32, name = 'input_aud')\n",
    "input_total = tf.concat([input_vis, input_aud], axis = -1)\n",
    "\n",
    "num_hidden_sensorymotor = 10\n",
    "hidden_sensorymotor = tf.contrib.layers.fully_connected(input_total, num_hidden_sensorymotor, activation_fn = tf.nn.relu)\n",
    "num_out_sensorymotor = 2\n",
    "out_sensorymotor = tf.contrib.layers.fully_connected(hidden_sensorymotor, num_out_sensorymotor, activation_fn = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just train the sensory-motor system to ignore audition\n",
    "run_sensorymotor_test = False\n",
    "\n",
    "if run_sensorymotor_test:\n",
    "    loss = tf.reduce_mean(tf.norm(out_sensorymotor-input_vis))\n",
    "    learning_rate = 0.01\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op=optimizer.minimize(loss)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    num_inputs = batch_size*num_batches\n",
    "    \n",
    "    in_vis_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_inputs)] \n",
    "    in_vis_list = np.reshape(in_vis_list_unshaped, [num_batches,batch_size,2])\n",
    "    \n",
    "    in_aud_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_inputs)]\n",
    "    in_aud_list = np.reshape(in_aud_list_unshaped, [num_batches,batch_size,2])\n",
    "\n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        in_vis_list_batch = in_vis_list[i]\n",
    "        in_aud_list_batch = in_aud_list[i]\n",
    "        l, it, os, _ =  sess.run([loss, input_total, out_sensorymotor, train_op], feed_dict = {input_vis:in_vis_list_batch, input_aud:in_aud_list_batch})\n",
    "        losses.append(l)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Loss function versus number of batches\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a feedforward NN representing the sensory-motor system with an ancillary rule label input\n",
    "\n",
    "input_vis = tf.placeholder(shape=[batch_size, 2], dtype=tf.float32, name = 'input_vis')\n",
    "input_aud = tf.placeholder(shape=[batch_size, 2], dtype=tf.float32, name = 'input_aud')\n",
    "input_cue = tf.placeholder(shape=[batch_size, 1], dtype=tf.float32, name = 'input_cue')\n",
    "input_total = tf.concat([input_vis, input_aud, input_cue], axis = -1)\n",
    "\n",
    "num_hidden_sensorymotor = 10\n",
    "hidden_sensorymotor = tf.contrib.layers.fully_connected(input_total, num_hidden_sensorymotor, activation_fn = tf.nn.relu)\n",
    "num_out_sensorymotor = 2\n",
    "out_sensorymotor = tf.contrib.layers.fully_connected(hidden_sensorymotor, num_out_sensorymotor, activation_fn = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the sensory-motor system to follow the given rule\n",
    "run_sensorymotor_rule_test = False\n",
    "\n",
    "if run_sensorymotor_rule_test:    \n",
    "    \n",
    "    num_inputs = batch_size*num_batches\n",
    "    \n",
    "    in_vis_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_inputs)] \n",
    "    in_vis_list = np.reshape(in_vis_list_unshaped, [num_batches,batch_size,2])\n",
    "    \n",
    "    in_aud_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_inputs)]\n",
    "    in_aud_list = np.reshape(in_aud_list_unshaped, [num_batches,batch_size,2])\n",
    "    \n",
    "    cue_list_unshaped = [[np.random.rand()] for k in range(num_inputs)]\n",
    "    in_cue_list = np.reshape(cue_list_unshaped, [num_batches,batch_size,1])\n",
    "                \n",
    "    learning_rate = 0.01\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        in_vis_list_batch = in_vis_list[i]\n",
    "        in_aud_list_batch = in_aud_list[i]\n",
    "        in_cue_list_batch = in_cue_list[i]\n",
    "        \n",
    "        loss = 0\n",
    "        for j in range(batch_size):\n",
    "            if in_cue_list_batch[j] > 0.5:\n",
    "                loss += tf.norm(tf.gather(out_sensorymotor-input_vis, [j]))\n",
    "            else:\n",
    "                loss += tf.norm(tf.gather(out_sensorymotor-input_aud, [j]))\n",
    "        \n",
    "        train_op=optimizer.minimize(loss)\n",
    "        \n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        l, it, os, _ =  sess.run([loss, input_total, out_sensorymotor, train_op], feed_dict = {input_vis:in_vis_list_batch, input_aud:in_aud_list_batch, input_cue:in_cue_list_batch})\n",
    "        losses.append(l)\n",
    "        print l\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Loss function versus number of batches\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we will create a mapping from cues to rules\n",
    "# The rule associated with each cue will change with time and a RNN will have to learn and remember the recent mapping\n",
    "# while not hanging onto it too long as the mapping changes\n",
    "\n",
    "# Define an RNN representing the PFC\n",
    "\n",
    "if False: # Do we run this block\n",
    "\n",
    "    num_units_PFC = 5\n",
    "\n",
    "    PFC_cell = tf.contrib.rnn.LSTMBlockCell(num_units = num_units_PFC)\n",
    "    PFC_state_previous = PFC_cell.zero_state(batch_size, tf.float32) # Initial state of PFC\n",
    "\n",
    "    # This does one cycle of the RNN\n",
    "    def PFC_step(input_data, network_state):\n",
    "        with tf.variable_scope(\"PFC\", reuse=False):\n",
    "            return PFC_cell(inputs = input_data, state = network_state) \n",
    "\n",
    "    # Cue inputs\n",
    "\n",
    "    num_timesteps = 5\n",
    "    cue_timeseries = tf.placeholder(shape=[batch_size, num_timesteps, 1], dtype=tf.float32, name = 'cues_timeseries')\n",
    "\n",
    "    for t in range(num_timesteps):\n",
    "\n",
    "        current_cue = cue_timeseries[:,t]\n",
    "\n",
    "        PFC_state = PFC_step(input_data = current_cue, network_state = PFC_state_previous)\n",
    "        # The output from the PFC into the sensorymotor system will be what we were previously calling the cue variable\n",
    "        # We'll now call it the rule\n",
    "        PFC_output = tf.contrib.layers.fully_connected(PFC_state[0], 1, activation_fn = tf.nn.relu)\n",
    "\n",
    "        PFC_state_previous = PFC_state[1]\n",
    "\n",
    "    sess = tf.Session()\n",
    "\n",
    "    ct = np.reshape([np.random.rand() for k in range(num_timesteps * batch_size * num_batches)], [num_batches, batch_size, num_timesteps, 1])\n",
    "\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for b in range(num_batches):\n",
    "\n",
    "        ct_in = ct[b, :, :]\n",
    "\n",
    "        o = sess.run([PFC_output], feed_dict = {cue_timeseries:ct_in})\n",
    "\n",
    "        print o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 30.337461\n",
      "\n",
      "\n",
      "\n",
      "timestep 0\n",
      "out [[ 0.45719886  0.49725309]\n",
      " [ 0.54027086  0.05616803]\n",
      " [ 0.78132749  0.41998348]\n",
      " [ 0.28797203  0.20161538]\n",
      " [ 0.49700922  0.42345381]\n",
      " [ 0.11584595  0.64713508]\n",
      " [ 0.40304333  0.33437955]\n",
      " [ 0.33134043  0.54227477]\n",
      " [ 0.46643996  0.39061856]\n",
      " [ 0.74599737  0.15143912]\n",
      " [ 0.4009662   0.57256395]\n",
      " [ 0.1411619   0.15160388]\n",
      " [ 0.53633052  0.59321696]\n",
      " [ 0.19374557  0.42294234]\n",
      " [ 0.67364705  0.15481785]\n",
      " [ 0.57772851  0.00488169]] \n",
      "vis in [[ 0.37185347  0.71853742]\n",
      " [ 0.53973028  0.00735999]\n",
      " [ 0.88337413  0.81285716]\n",
      " [ 0.55818585  0.06547872]\n",
      " [ 0.72390674  0.66367936]\n",
      " [ 0.03968921  0.91704169]\n",
      " [ 0.50738132  0.42772615]\n",
      " [ 0.06714081  0.72939077]\n",
      " [ 0.33205646  0.20465546]\n",
      " [ 0.83442935  0.44912635]\n",
      " [ 0.77631461  0.45224893]\n",
      " [ 0.0353363   0.07140771]\n",
      " [ 0.43645014  0.56579395]\n",
      " [ 0.34937572  0.82405574]\n",
      " [ 0.82451224  0.08318734]\n",
      " [ 0.72575876  0.03220653]] \n",
      "aud in [[ 0.73044017  0.51665823]\n",
      " [ 0.70300913  0.2602054 ]\n",
      " [ 0.85788734  0.30635225]\n",
      " [ 0.06884449  0.54439786]\n",
      " [ 0.41178037  0.43362786]\n",
      " [ 0.31497478  0.63756676]\n",
      " [ 0.43207204  0.46429533]\n",
      " [ 0.80570401  0.57722539]\n",
      " [ 0.74679345  0.81080203]\n",
      " [ 0.81130938  0.08519732]\n",
      " [ 0.11115031  0.96750508]\n",
      " [ 0.3482154   0.39264365]\n",
      " [ 0.81396464  0.88952431]\n",
      " [ 0.18662926  0.22456221]\n",
      " [ 0.67395167  0.42171024]\n",
      " [ 0.61938603  0.09606   ]] \n",
      "rule chosen [1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0] \n",
      "correct rule [1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0]\n",
      "\n",
      "\n",
      "timestep 1\n",
      "out [[ 0.          0.69451183]\n",
      " [ 0.          0.47660461]\n",
      " [ 0.          0.70662409]\n",
      " [ 0.          0.25338227]\n",
      " [ 0.          0.14398779]\n",
      " [ 0.          0.12385953]\n",
      " [ 0.          0.73204607]\n",
      " [ 0.          0.26054674]\n",
      " [ 0.          0.49804589]\n",
      " [ 0.          0.75200707]\n",
      " [ 0.          0.65955508]\n",
      " [ 0.          0.38581002]\n",
      " [ 0.          0.56127214]\n",
      " [ 0.          0.26156893]\n",
      " [ 0.          0.25635552]\n",
      " [ 0.          0.58457011]] \n",
      "vis in [[ 0.21626726  0.48155086]\n",
      " [ 0.65052806  0.81414691]\n",
      " [ 0.1272194   0.70416253]\n",
      " [ 0.87802923  0.08794873]\n",
      " [ 0.18120983  0.00748983]\n",
      " [ 0.49392793  0.10864575]\n",
      " [ 0.50969254  0.52702492]\n",
      " [ 0.84884391  0.1454738 ]\n",
      " [ 0.66437823  0.40342401]\n",
      " [ 0.93469893  0.84205443]\n",
      " [ 0.31254533  0.88931972]\n",
      " [ 0.72710056  0.77242085]\n",
      " [ 0.18841136  0.57855238]\n",
      " [ 0.95576636  0.36393875]\n",
      " [ 0.61777965  0.30427648]\n",
      " [ 0.04201476  0.62808257]] \n",
      "aud in [[ 0.21781214  0.96819543]\n",
      " [ 0.78219429  0.18350229]\n",
      " [ 0.86592862  0.9032235 ]\n",
      " [ 0.50675535  0.48786494]\n",
      " [ 0.48372007  0.58320457]\n",
      " [ 0.99782414  0.39471967]\n",
      " [ 0.26552854  0.89992294]\n",
      " [ 0.87936447  0.47842012]\n",
      " [ 0.71599157  0.71128275]\n",
      " [ 0.6794708   0.85319824]\n",
      " [ 0.57885627  0.24268969]\n",
      " [ 0.32361187  0.24231486]\n",
      " [ 0.09039247  0.61801152]\n",
      " [ 0.23610456  0.35019756]\n",
      " [ 0.00992768  0.29582452]\n",
      " [ 0.13034866  0.49977171]] \n",
      "rule chosen [1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0] \n",
      "correct rule [1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "\n",
      "\n",
      "timestep 2\n",
      "out [[ 0.42243198  0.36975101]\n",
      " [ 0.20753035  0.52055383]\n",
      " [ 0.60859811  0.44667554]\n",
      " [ 0.42790765  0.52767742]\n",
      " [ 0.58017224  0.87322032]\n",
      " [ 0.51290375  0.92660385]\n",
      " [ 0.47520757  0.38238287]\n",
      " [ 0.67130727  0.33475232]\n",
      " [ 0.53898084  0.31816784]\n",
      " [ 0.56527954  0.84631598]\n",
      " [ 0.5229435   0.76164162]\n",
      " [ 0.43660706  0.71306098]\n",
      " [ 0.62124705  0.27871594]\n",
      " [ 0.64323294  0.64606524]\n",
      " [ 0.75119621  0.77337497]\n",
      " [ 0.31751889  0.6932205 ]] \n",
      "vis in [[ 0.54551007  0.15205962]\n",
      " [ 0.19472286  0.37069688]\n",
      " [ 0.58356168  0.47129093]\n",
      " [ 0.16405034  0.68226602]\n",
      " [ 0.20605279  0.98862147]\n",
      " [ 0.62247275  0.94170733]\n",
      " [ 0.4030696   0.52725651]\n",
      " [ 0.42144561  0.58692734]\n",
      " [ 0.55711616  0.25568366]\n",
      " [ 0.14732097  0.93020436]\n",
      " [ 0.19742162  0.90239292]\n",
      " [ 0.69757929  0.83536251]\n",
      " [ 0.18053942  0.52968102]\n",
      " [ 0.5357939   0.84218822]\n",
      " [ 0.97103318  0.86927892]\n",
      " [ 0.06872858  0.78214148]] \n",
      "aud in [[ 0.25652016  0.60990402]\n",
      " [ 0.18741676  0.68408055]\n",
      " [ 0.55991507  0.45816223]\n",
      " [ 0.58949339  0.39812064]\n",
      " [ 0.87024517  0.82736783]\n",
      " [ 0.34435135  0.9433699 ]\n",
      " [ 0.46704177  0.26606835]\n",
      " [ 0.88555446  0.0941446 ]\n",
      " [ 0.45875473  0.40412735]\n",
      " [ 0.89284908  0.8224477 ]\n",
      " [ 0.7568389   0.6754687 ]\n",
      " [ 0.08989811  0.58111645]\n",
      " [ 0.98274291  0.02650811]\n",
      " [ 0.65904498  0.50500746]\n",
      " [ 0.4208032   0.71936685]\n",
      " [ 0.46195217  0.60588855]] \n",
      "rule chosen [2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0] \n",
      "correct rule [2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0]\n",
      "\n",
      "\n",
      "timestep 3\n",
      "out [[ 0.03576254  0.45275736]\n",
      " [ 0.70116061  0.5461989 ]\n",
      " [ 0.44760191  0.        ]\n",
      " [ 0.33911571  0.20308962]\n",
      " [ 0.84271622  0.87906367]\n",
      " [ 0.0182206   0.56213814]\n",
      " [ 0.16394676  0.62756962]\n",
      " [ 0.78468037  0.8651492 ]\n",
      " [ 0.55276096  0.33672836]\n",
      " [ 0.90990222  0.26660907]\n",
      " [ 0.23895915  0.11538528]\n",
      " [ 0.99244916  0.14607681]\n",
      " [ 0.45566079  0.0647154 ]\n",
      " [ 0.55904502  0.35979295]\n",
      " [ 0.96940935  0.84115189]\n",
      " [ 0.90570557  0.45828855]] \n",
      "vis in [[ 0.99394098  0.40123239]\n",
      " [ 0.58788799  0.22368841]\n",
      " [ 0.67258853  0.6307708 ]\n",
      " [ 0.33387279  0.18903457]\n",
      " [ 0.83005478  0.83398984]\n",
      " [ 0.22056481  0.34826197]\n",
      " [ 0.14914838  0.59354844]\n",
      " [ 0.7634694   0.81178642]\n",
      " [ 0.14611043  0.40390713]\n",
      " [ 0.17500531  0.39456209]\n",
      " [ 0.8149855   0.09654323]\n",
      " [ 0.98506237  0.12331308]\n",
      " [ 0.92939014  0.43859676]\n",
      " [ 0.55540521  0.33193554]\n",
      " [ 0.2662391   0.00538492]\n",
      " [ 0.28598787  0.34999473]] \n",
      "aud in [[ 0.03178647  0.46973852]\n",
      " [ 0.70909572  0.55533162]\n",
      " [ 0.44672811  0.02837757]\n",
      " [ 0.19282986  0.03049431]\n",
      " [ 0.63704427  0.78741253]\n",
      " [ 0.02314232  0.57410806]\n",
      " [ 0.62218736  0.98646832]\n",
      " [ 0.6507547   0.80357984]\n",
      " [ 0.55578224  0.35014465]\n",
      " [ 0.9199111   0.28533242]\n",
      " [ 0.23840054  0.13708127]\n",
      " [ 0.2103081   0.83315116]\n",
      " [ 0.45046351  0.09068577]\n",
      " [ 0.84524762  0.5037581 ]\n",
      " [ 0.98723899  0.85890216]\n",
      " [ 0.91521857  0.46965889]] \n",
      "rule chosen [2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0] \n",
      "correct rule [2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0]\n",
      "\n",
      "\n",
      "timestep 4\n",
      "out [[ 0.13962317  0.27390605]\n",
      " [ 0.95496345  0.75841337]\n",
      " [ 0.275942    0.09698737]\n",
      " [ 0.95856333  0.80728084]\n",
      " [ 0.11365687  0.56329489]\n",
      " [ 0.94314128  0.18358466]\n",
      " [ 0.06923856  0.8397522 ]\n",
      " [ 0.46589339  0.17482749]\n",
      " [ 0.67970842  0.84308779]\n",
      " [ 0.41687393  0.47325656]\n",
      " [ 0.20333715  0.93619126]\n",
      " [ 0.45003802  0.64109343]\n",
      " [ 0.27716249  0.34661373]\n",
      " [ 0.          0.06422576]\n",
      " [ 0.17808925  0.71555233]\n",
      " [ 0.87417758  0.44802409]] \n",
      "vis in [[ 0.14332704  0.29800214]\n",
      " [ 0.98314504  0.7866034 ]\n",
      " [ 0.28082744  0.10758853]\n",
      " [ 0.95982436  0.85095702]\n",
      " [ 0.81425635  0.93189754]\n",
      " [ 0.94954976  0.2189475 ]\n",
      " [ 0.36073337  0.22289419]\n",
      " [ 0.47229402  0.19693868]\n",
      " [ 0.7169701   0.43783758]\n",
      " [ 0.0543508   0.16005626]\n",
      " [ 0.18950342  0.97799137]\n",
      " [ 0.26249973  0.7742758 ]\n",
      " [ 0.27960873  0.38056178]\n",
      " [ 0.42967064  0.2731392 ]\n",
      " [ 0.80469994  0.82439161]\n",
      " [ 0.01383893  0.30791157]] \n",
      "aud in [[  4.01387223e-01   5.19703631e-01]\n",
      " [  2.89000300e-01   2.18315690e-01]\n",
      " [  2.13205677e-01   1.95982438e-02]\n",
      " [  9.85940952e-01   7.68667023e-01]\n",
      " [  1.20962537e-01   5.69051673e-01]\n",
      " [  7.93891864e-01   6.95851697e-01]\n",
      " [  7.14821357e-02   8.42662968e-01]\n",
      " [  4.37345290e-01   3.48781849e-01]\n",
      " [  6.81865168e-01   8.50959387e-01]\n",
      " [  4.15622094e-01   4.76732161e-01]\n",
      " [  9.60436960e-01   8.64697397e-01]\n",
      " [  4.54951055e-01   6.47211923e-01]\n",
      " [  5.63872766e-01   9.42722992e-01]\n",
      " [  8.59328554e-05   6.53169158e-02]\n",
      " [  1.83611473e-01   7.21895667e-01]\n",
      " [  8.72748816e-01   4.54377202e-01]] \n",
      "rule chosen [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0] \n",
      "correct rule [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0]\n",
      "\n",
      "\n",
      "timestep 5\n",
      "out [[ 0.60733545  0.51940966]\n",
      " [ 0.37716487  0.63494331]\n",
      " [ 0.5271886   0.49196327]\n",
      " [ 0.31265944  0.51397264]\n",
      " [ 0.52557468  0.60164493]\n",
      " [ 0.81067538  0.38031638]\n",
      " [ 0.88714558  0.75685924]\n",
      " [ 0.89416212  0.3103765 ]\n",
      " [ 0.55361968  0.94014943]\n",
      " [ 0.47537166  0.8543542 ]\n",
      " [ 0.99041164  0.99228889]\n",
      " [ 0.82134819  0.54273629]\n",
      " [ 0.94304001  0.12854563]\n",
      " [ 0.37961456  0.94896585]\n",
      " [ 0.13100772  0.92762756]\n",
      " [ 0.15744714  0.67903   ]] \n",
      "vis in [[ 0.44296798  0.20670516]\n",
      " [ 0.39356336  0.58802412]\n",
      " [ 0.54472225  0.443838  ]\n",
      " [ 0.31763202  0.49781133]\n",
      " [ 0.50550326  0.61199279]\n",
      " [ 0.82790662  0.3347085 ]\n",
      " [ 0.89958865  0.71261425]\n",
      " [ 0.91569657  0.28416676]\n",
      " [ 0.49236672  0.28905334]\n",
      " [ 0.77038361  0.00122829]\n",
      " [ 0.9993098   0.95378253]\n",
      " [ 0.83265422  0.49673098]\n",
      " [ 0.24903204  0.22617771]\n",
      " [ 0.75618778  0.38255771]\n",
      " [ 0.11511211  0.92405393]\n",
      " [ 0.16652209  0.64828188]] \n",
      "aud in [[ 0.64308265  0.49022479]\n",
      " [ 0.85620168  0.61710763]\n",
      " [ 0.83764547  0.70924258]\n",
      " [ 0.04483324  0.19655865]\n",
      " [ 0.56334693  0.57094134]\n",
      " [ 0.76683472  0.64463831]\n",
      " [ 0.53673921  0.75368212]\n",
      " [ 0.32270524  0.05580032]\n",
      " [ 0.59557372  0.89913458]\n",
      " [ 0.50977484  0.81954789]\n",
      " [ 0.46065502  0.47540245]\n",
      " [ 0.9672399   0.68971897]\n",
      " [ 0.98294596  0.10309786]\n",
      " [ 0.41685784  0.91219986]\n",
      " [ 0.04061166  0.22097824]\n",
      " [ 0.35059476  0.51112596]] \n",
      "rule chosen [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0] \n",
      "correct rule [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0]\n",
      "\n",
      "\n",
      "timestep 6\n",
      "out [[ 0.81096673  0.37669703]\n",
      " [ 0.50625342  0.25534767]\n",
      " [ 0.76427203  0.65065914]\n",
      " [ 0.42748699  0.21886502]\n",
      " [ 0.5447486   0.61002564]\n",
      " [ 0.59051746  0.40640372]\n",
      " [ 0.24874273  0.50784761]\n",
      " [ 0.85153484  0.65064669]\n",
      " [ 0.29438916  0.72176844]\n",
      " [ 0.56247169  0.45474112]\n",
      " [ 0.90079659  0.53418314]\n",
      " [ 0.7737422   0.79886568]\n",
      " [ 0.70036745  0.31290117]\n",
      " [ 0.47087795  0.77439773]\n",
      " [ 0.40066811  0.48747858]\n",
      " [ 0.43621585  0.42704424]] \n",
      "vis in [[ 0.92481419  0.4437309 ]\n",
      " [ 0.2471459   0.57003947]\n",
      " [ 0.75482978  0.7318872 ]\n",
      " [ 0.43541812  0.16633652]\n",
      " [ 0.76373244  0.55979366]\n",
      " [ 0.71889142  0.25536155]\n",
      " [ 0.1278165   0.85730736]\n",
      " [ 0.87603044  0.63565846]\n",
      " [ 0.23292017  0.99169875]\n",
      " [ 0.3995743   0.28019002]\n",
      " [ 0.98903931  0.80616483]\n",
      " [ 0.89214928  0.84069176]\n",
      " [ 0.77679429  0.49251884]\n",
      " [ 0.55196233  0.70403931]\n",
      " [ 0.2346954   0.40388282]\n",
      " [ 0.43364602  0.6081539 ]] \n",
      "aud in [[ 0.81616174  0.45066886]\n",
      " [ 0.81644703  0.0557771 ]\n",
      " [ 0.91202013  0.68209944]\n",
      " [ 0.45751558  0.3926704 ]\n",
      " [ 0.41608743  0.72378785]\n",
      " [ 0.55315983  0.67488195]\n",
      " [ 0.34506773  0.1745763 ]\n",
      " [ 0.96876222  0.81026924]\n",
      " [ 0.38029687  0.50738683]\n",
      " [ 0.80418767  0.76104756]\n",
      " [ 0.9328956   0.41989791]\n",
      " [ 0.82310104  0.83141084]\n",
      " [ 0.67066105  0.2318592 ]\n",
      " [ 0.49132773  0.907262  ]\n",
      " [ 0.6371328   0.65581485]\n",
      " [ 0.48049593  0.30022426]] \n",
      "rule chosen [2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0] \n",
      "correct rule [2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0]\n",
      "\n",
      "\n",
      "timestep 7\n",
      "out [[ 0.05510283  0.40700614]\n",
      " [ 0.24731392  0.19872789]\n",
      " [ 0.44055256  0.775002  ]\n",
      " [ 0.86412901  0.37639701]\n",
      " [ 0.25179935  0.86540002]\n",
      " [ 0.90393692  0.16700254]\n",
      " [ 0.9928546   0.81039351]\n",
      " [ 0.97294134  0.89387751]\n",
      " [ 0.1139731   0.52493036]\n",
      " [ 0.9148649   0.75817025]\n",
      " [ 0.06033283  0.42685479]\n",
      " [ 0.23489895  0.92344958]\n",
      " [ 0.57388741  0.44976059]\n",
      " [ 0.11510291  0.53013849]\n",
      " [ 0.0770269   0.15092057]\n",
      " [ 0.2335709   0.33310974]] \n",
      "vis in [[ 0.06554209  0.41792779]\n",
      " [ 0.2610782   0.21677572]\n",
      " [ 0.59896198  0.57564147]\n",
      " [ 0.18216957  0.68857284]\n",
      " [ 0.252934    0.8671517 ]\n",
      " [ 0.34456229  0.06726494]\n",
      " [ 0.99501248  0.81545395]\n",
      " [ 0.99212406  0.91082231]\n",
      " [ 0.23106956  0.34857114]\n",
      " [ 0.93556011  0.77732705]\n",
      " [ 0.01231424  0.54675386]\n",
      " [ 0.23407256  0.9243349 ]\n",
      " [ 0.5899681   0.47003706]\n",
      " [ 0.02242755  0.60222189]\n",
      " [ 0.10219744  0.17998976]\n",
      " [ 0.24943429  0.35120808]] \n",
      "aud in [[ 0.31657246  0.82740198]\n",
      " [ 0.5118836   0.01052407]\n",
      " [ 0.43671225  0.78719031]\n",
      " [ 0.86132097  0.40072514]\n",
      " [ 0.22321681  0.41128115]\n",
      " [ 0.90269064  0.19380201]\n",
      " [ 0.37267033  0.7586038 ]\n",
      " [ 0.99263421  0.9616118 ]\n",
      " [ 0.1070734   0.52440199]\n",
      " [ 0.97939876  0.91002355]\n",
      " [ 0.05131501  0.4255451 ]\n",
      " [ 0.15031312  0.51651736]\n",
      " [ 0.67735705  0.94905014]\n",
      " [ 0.10654649  0.52948058]\n",
      " [ 0.82219058  0.79960049]\n",
      " [ 0.53441675  0.87871268]] \n",
      "rule chosen [1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0] \n",
      "correct rule [1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0]\n",
      "\n",
      "\n",
      "timestep 8\n",
      "out [[ 0.10648208  0.83680797]\n",
      " [ 0.42544389  0.84359384]\n",
      " [ 0.35428172  0.43987018]\n",
      " [ 0.80933213  0.50307679]\n",
      " [ 0.38447338  0.47525635]\n",
      " [ 0.35151529  0.66143894]\n",
      " [ 0.57044661  0.33682698]\n",
      " [ 0.65638214  0.83901078]\n",
      " [ 0.30699116  0.60646361]\n",
      " [ 0.54583412  0.17950448]\n",
      " [ 0.29832178  0.54629463]\n",
      " [ 0.71506524  0.27451575]\n",
      " [ 0.31480825  0.54268694]\n",
      " [ 0.4200629   0.31744727]\n",
      " [ 0.43226254  0.50217205]\n",
      " [ 0.50064218  0.40158525]] \n",
      "vis in [[ 0.00533689  0.95181102]\n",
      " [ 0.08174758  0.86965376]\n",
      " [ 0.45071339  0.83490919]\n",
      " [ 0.49881422  0.87441587]\n",
      " [ 0.23359143  0.72482943]\n",
      " [ 0.90446362  0.37776439]\n",
      " [ 0.34229707  0.86529389]\n",
      " [ 0.16145583  0.72252294]\n",
      " [ 0.35317553  0.40262569]\n",
      " [ 0.22727714  0.15921948]\n",
      " [ 0.67620092  0.79454022]\n",
      " [ 0.52639923  0.60024174]\n",
      " [ 0.37513912  0.53693541]\n",
      " [ 0.80528606  0.35008465]\n",
      " [ 0.43560017  0.48835284]\n",
      " [ 0.088703    0.26098844]] \n",
      "aud in [[ 0.12350506  0.73263501]\n",
      " [ 0.6666419   0.79822941]\n",
      " [ 0.28753411  0.21059557]\n",
      " [ 0.96487402  0.3253636 ]\n",
      " [ 0.45974694  0.33655212]\n",
      " [ 0.00279405  0.81572749]\n",
      " [ 0.68414217  0.03731593]\n",
      " [ 0.95112105  0.92204084]\n",
      " [ 0.29232718  0.75763924]\n",
      " [ 0.68449441  0.26184584]\n",
      " [ 0.07284665  0.37338395]\n",
      " [ 0.77864226  0.13732574]\n",
      " [ 0.28454458  0.56794326]\n",
      " [ 0.16447464  0.30778814]\n",
      " [ 0.40329798  0.55535084]\n",
      " [ 0.72656833  0.52730991]] \n",
      "rule chosen [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0] \n",
      "correct rule [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0]\n",
      "\n",
      "\n",
      "timestep 9\n",
      "out [[ 0.53002965  0.14895821]\n",
      " [ 0.12832327  0.84310883]\n",
      " [ 0.76844591  0.6705538 ]\n",
      " [ 0.55188096  0.9794125 ]\n",
      " [ 0.37718555  0.68856215]\n",
      " [ 0.60680509  0.48150092]\n",
      " [ 0.1277082   0.74463564]\n",
      " [ 0.56477451  0.48611361]\n",
      " [ 0.66087049  0.74730068]\n",
      " [ 0.36173171  0.60729945]\n",
      " [ 0.37882665  0.824076  ]\n",
      " [ 0.52945131  0.63857138]\n",
      " [ 0.68481326  0.31033719]\n",
      " [ 0.1102588   0.47212142]\n",
      " [ 0.24855648  0.53111279]\n",
      " [ 0.6665706   0.83432591]] \n",
      "vis in [[  7.06195802e-01   6.92491823e-02]\n",
      " [  8.52795244e-04   7.92295255e-01]\n",
      " [  7.39100050e-01   9.71400308e-01]\n",
      " [  7.21740313e-01   8.83878873e-01]\n",
      " [  7.36100731e-01   8.74939330e-01]\n",
      " [  3.77897499e-01   2.25545910e-01]\n",
      " [  6.42559889e-02   5.22425081e-01]\n",
      " [  2.41363755e-01   3.47821356e-01]\n",
      " [  7.26975698e-01   5.24402283e-01]\n",
      " [  5.26941081e-01   8.20952304e-01]\n",
      " [  9.49401874e-03   7.69075630e-01]\n",
      " [  1.87249562e-01   5.92548552e-01]\n",
      " [  5.83610857e-01   2.80637322e-01]\n",
      " [  2.78529298e-02   3.41269707e-01]\n",
      " [  2.22039069e-01   5.64464266e-01]\n",
      " [  8.47040186e-01   6.28408624e-01]] \n",
      "aud in [[ 0.26320897  0.15579219]\n",
      " [ 0.16157165  0.85501188]\n",
      " [ 0.86729707  0.19306296]\n",
      " [ 0.39878899  0.97955884]\n",
      " [ 0.02448009  0.40691376]\n",
      " [ 0.82822878  0.66920875]\n",
      " [ 0.13544737  0.91584208]\n",
      " [ 0.91692921  0.51545422]\n",
      " [ 0.57569473  0.91238469]\n",
      " [ 0.22856507  0.27097643]\n",
      " [ 0.7035994   0.80146812]\n",
      " [ 0.93217199  0.54050528]\n",
      " [ 0.77336976  0.25954647]\n",
      " [ 0.16919004  0.53911974]\n",
      " [ 0.30287927  0.38511774]\n",
      " [ 0.46193261  0.98690713]] \n",
      "rule chosen [1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0] \n",
      "correct rule [1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEKCAYAAAD0Luk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13d9180d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we will create a mapping from cues to rules\n",
    "# The rule associated with each cue will change with time and a RNN will have to learn and remember the recent mapping\n",
    "# while not hanging onto it too long as the mapping changes\n",
    "\n",
    "# Define an RNN representing the PFC\n",
    "\n",
    "num_units_PFC = 20\n",
    "\n",
    "PFC_cell = tf.contrib.rnn.LSTMBlockCell(num_units = num_units_PFC)\n",
    "PFC_state_previous = PFC_cell.zero_state(batch_size, tf.float32) # Initial state of PFC\n",
    "\n",
    "# This does one cycle of the RNN\n",
    "def PFC_step(input_data, network_state):\n",
    "    with tf.variable_scope(\"PFC\", reuse=False):\n",
    "        return PFC_cell(inputs = input_data, state = network_state) \n",
    "    \n",
    "# Cue inputs\n",
    "\n",
    "num_timesteps = 10\n",
    "cue_timeseries = tf.placeholder(shape=[batch_size, num_timesteps, 1], dtype=tf.float32, name = 'cues_timeseries')\n",
    "\n",
    "input_vis = tf.placeholder(shape=[batch_size, num_timesteps, 2], dtype=tf.float32, name = 'input_vis')\n",
    "input_aud = tf.placeholder(shape=[batch_size, num_timesteps, 2], dtype=tf.float32, name = 'input_aud')\n",
    "\n",
    "def rvis():\n",
    "    return 1.0\n",
    "def raud():\n",
    "    return 2.0\n",
    "def rnull():\n",
    "    return 0.0\n",
    "\n",
    "def cue_to_rule_mapping_function(t, integer_input): # Define a changing mapping from cues to rules\n",
    "    \n",
    "    if t % 10 < 10: # Always true here but we'll make this change later -- we can use this to set up time-dependent cue-to-rule mappings\n",
    "        r1 = tf.cond(tf.equal(integer_input, tf.constant(0, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "    \n",
    "        r2 = tf.cond(tf.equal(integer_input, tf.constant(1, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "        \n",
    "        r3 = tf.cond(tf.equal(integer_input, tf.constant(2, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "        \n",
    "        r4 = tf.cond(tf.equal(integer_input, tf.constant(3, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "    else: # We can use this to set up time-dependent cue-to-rule mappings\n",
    "        r1 = tf.cond(tf.equal(integer_input, tf.constant(0, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "    \n",
    "        r2 = tf.cond(tf.equal(integer_input, tf.constant(1, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "        \n",
    "        r3 = tf.cond(tf.equal(integer_input, tf.constant(2, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "        \n",
    "        r4 = tf.cond(tf.equal(integer_input, tf.constant(3, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "        \n",
    "    return tf.reduce_max([r1,r2,r3,r4])\n",
    "\n",
    "loss = 0\n",
    "\n",
    "outs = []\n",
    "\n",
    "rules_chosen = []\n",
    "\n",
    "for t in range(num_timesteps):\n",
    "\n",
    "    current_cue = cue_timeseries[:,t]\n",
    "\n",
    "    PFC_state = PFC_step(input_data = current_cue, network_state = PFC_state_previous)\n",
    "    # The output from the PFC into the sensorymotor system will be what we were previously calling the cue variable\n",
    "    # We'll now call it the rule\n",
    "    PFC_output = tf.contrib.layers.fully_connected(PFC_state[0], 1, activation_fn = tf.nn.relu)\n",
    "    \n",
    "    input_cue_to_sm_sys = PFC_output\n",
    "    input_total = tf.concat([input_vis[:,t], input_aud[:,t], input_cue_to_sm_sys], axis = -1)\n",
    "    \n",
    "    num_hidden_sensorymotor = 20\n",
    "    hidden_sensorymotor = tf.contrib.layers.fully_connected(input_total, num_hidden_sensorymotor, activation_fn = tf.nn.relu)\n",
    "    num_out_sensorymotor = 2\n",
    "    out_sensorymotor = tf.contrib.layers.fully_connected(hidden_sensorymotor, num_out_sensorymotor, activation_fn = tf.nn.relu)\n",
    "    \n",
    "    PFC_state_previous = PFC_state[1]\n",
    "    \n",
    "    rul_chose = []\n",
    "    for e in range(batch_size):\n",
    "        cc = current_cue[e][0]\n",
    "        cue_to_rule_mapping_function_output = cue_to_rule_mapping_function(t, cc)\n",
    "        if t>=0: # Always true here but we'll make this change later -- we can use this to set up time-dependent loss functions, e.g., only look at late times\n",
    "            loss_contrib = tf.cond(tf.equal(cue_to_rule_mapping_function_output, tf.constant(1, dtype = tf.float32)), true_fn = lambda: tf.norm(input_vis[e,t] - out_sensorymotor[e]),  false_fn = lambda: tf.norm(input_aud[e,t] - out_sensorymotor[e]))\n",
    "            loss += loss_contrib\n",
    "        rul_chose.append(cue_to_rule_mapping_function_output)\n",
    "    rules_chosen.append(rul_chose)\n",
    "\n",
    "    outs.append(out_sensorymotor)\n",
    "        \n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op=optimizer.minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Random cue\n",
    "ct = np.reshape([np.random.randint(0,4) for k in range(num_timesteps * batch_size * num_batches)], [num_batches, batch_size, num_timesteps, 1])\n",
    "    \n",
    "in_vis_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_timesteps * batch_size * num_batches)] \n",
    "in_vis_list = np.reshape(in_vis_list_unshaped, [num_batches,batch_size,num_timesteps, 2])\n",
    "\n",
    "in_aud_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_timesteps * batch_size * num_batches)]\n",
    "in_aud_list = np.reshape(in_aud_list_unshaped, [num_batches,batch_size,num_timesteps, 2])\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "losses = []\n",
    "\n",
    "for b in range(num_batches): # Just testing\n",
    "        \n",
    "    ct_in = ct[b, :, :]\n",
    "\n",
    "    in_v = in_vis_list[b, :, :]\n",
    "\n",
    "    in_a = in_aud_list[b, :, :]\n",
    "\n",
    "    os, l, rc, _ = sess.run([outs, loss, rules_chosen, train_op], feed_dict = {cue_timeseries:ct_in, input_vis: in_v, input_aud:in_a})\n",
    "    # The outputs here are just for the last batch...\n",
    "    losses.append(l)\n",
    "    \n",
    "print \"Loss: %f\" %l\n",
    "print \"\\n\\n\"\n",
    "for q in range(num_timesteps):\n",
    "    print \"timestep %i\" % q\n",
    "    print \"out\", os[:][q], \"\\n\", \"vis in\", in_v[:,q],\"\\n\", \"aud in\", in_a[:, q],\"\\n\", \"rule chosen\", rc[:][q],\"\\n\", \"correct rule\", [sess.run(cue_to_rule_mapping_function(q, float(ct_in[e,q]))) for e in range(batch_size)]  \n",
    "    print \"\\n\"\n",
    "        \n",
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.title(\"Loss versus # batches\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
