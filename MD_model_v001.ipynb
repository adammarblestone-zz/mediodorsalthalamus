{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammarblestone/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_batches = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a feedforward NN representing the sensory-motor system\n",
    "\n",
    "input_vis = tf.placeholder(shape=[batch_size, 2], dtype=tf.float32, name = 'input_vis')\n",
    "input_aud = tf.placeholder(shape=[batch_size, 2], dtype=tf.float32, name = 'input_aud')\n",
    "input_total = tf.concat([input_vis, input_aud], axis = -1)\n",
    "\n",
    "num_hidden_sensorymotor = 10\n",
    "hidden_sensorymotor = tf.contrib.layers.fully_connected(input_total, num_hidden_sensorymotor, activation_fn = tf.nn.relu)\n",
    "num_out_sensorymotor = 2\n",
    "out_sensorymotor = tf.contrib.layers.fully_connected(hidden_sensorymotor, num_out_sensorymotor, activation_fn = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just train the sensory-motor system to ignore audition\n",
    "run_sensorymotor_test = False\n",
    "\n",
    "if run_sensorymotor_test:\n",
    "    loss = tf.reduce_mean(tf.norm(out_sensorymotor-input_vis))\n",
    "    learning_rate = 0.01\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op=optimizer.minimize(loss)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    num_inputs = batch_size*num_batches\n",
    "    \n",
    "    in_vis_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_inputs)] \n",
    "    in_vis_list = np.reshape(in_vis_list_unshaped, [num_batches,batch_size,2])\n",
    "    \n",
    "    in_aud_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_inputs)]\n",
    "    in_aud_list = np.reshape(in_aud_list_unshaped, [num_batches,batch_size,2])\n",
    "\n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        in_vis_list_batch = in_vis_list[i]\n",
    "        in_aud_list_batch = in_aud_list[i]\n",
    "        l, it, os, _ =  sess.run([loss, input_total, out_sensorymotor, train_op], feed_dict = {input_vis:in_vis_list_batch, input_aud:in_aud_list_batch})\n",
    "        losses.append(l)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Loss function versus number of batches\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a feedforward NN representing the sensory-motor system with an ancillary rule label input\n",
    "\n",
    "input_vis = tf.placeholder(shape=[batch_size, 2], dtype=tf.float32, name = 'input_vis')\n",
    "input_aud = tf.placeholder(shape=[batch_size, 2], dtype=tf.float32, name = 'input_aud')\n",
    "input_cue = tf.placeholder(shape=[batch_size, 1], dtype=tf.float32, name = 'input_cue')\n",
    "input_total = tf.concat([input_vis, input_aud, input_cue], axis = -1)\n",
    "\n",
    "num_hidden_sensorymotor = 10\n",
    "hidden_sensorymotor = tf.contrib.layers.fully_connected(input_total, num_hidden_sensorymotor, activation_fn = tf.nn.relu)\n",
    "num_out_sensorymotor = 2\n",
    "out_sensorymotor = tf.contrib.layers.fully_connected(hidden_sensorymotor, num_out_sensorymotor, activation_fn = tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the sensory-motor system to follow the given rule\n",
    "run_sensorymotor_rule_test = False\n",
    "\n",
    "if run_sensorymotor_rule_test:    \n",
    "    \n",
    "    num_inputs = batch_size*num_batches\n",
    "    \n",
    "    in_vis_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_inputs)] \n",
    "    in_vis_list = np.reshape(in_vis_list_unshaped, [num_batches,batch_size,2])\n",
    "    \n",
    "    in_aud_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_inputs)]\n",
    "    in_aud_list = np.reshape(in_aud_list_unshaped, [num_batches,batch_size,2])\n",
    "    \n",
    "    cue_list_unshaped = [[np.random.rand()] for k in range(num_inputs)]\n",
    "    in_cue_list = np.reshape(cue_list_unshaped, [num_batches,batch_size,1])\n",
    "                \n",
    "    learning_rate = 0.01\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    losses = []\n",
    "    for i in range(num_batches):\n",
    "        in_vis_list_batch = in_vis_list[i]\n",
    "        in_aud_list_batch = in_aud_list[i]\n",
    "        in_cue_list_batch = in_cue_list[i]\n",
    "        \n",
    "        loss = 0\n",
    "        for j in range(batch_size):\n",
    "            if in_cue_list_batch[j] > 0.5:\n",
    "                loss += tf.norm(tf.gather(out_sensorymotor-input_vis, [j]))\n",
    "            else:\n",
    "                loss += tf.norm(tf.gather(out_sensorymotor-input_aud, [j]))\n",
    "        \n",
    "        train_op=optimizer.minimize(loss)\n",
    "        \n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        l, it, os, _ =  sess.run([loss, input_total, out_sensorymotor, train_op], feed_dict = {input_vis:in_vis_list_batch, input_aud:in_aud_list_batch, input_cue:in_cue_list_batch})\n",
    "        losses.append(l)\n",
    "        print l\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Loss function versus number of batches\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we will create a mapping from cues to rules\n",
    "# The rule associated with each cue will change with time and a RNN will have to learn and remember the recent mapping\n",
    "# while not hanging onto it too long as the mapping changes\n",
    "\n",
    "# Define an RNN representing the PFC\n",
    "\n",
    "if False: # Do we run this block\n",
    "\n",
    "    num_units_PFC = 5\n",
    "\n",
    "    PFC_cell = tf.contrib.rnn.LSTMBlockCell(num_units = num_units_PFC)\n",
    "    PFC_state_previous = PFC_cell.zero_state(batch_size, tf.float32) # Initial state of PFC\n",
    "\n",
    "    # This does one cycle of the RNN\n",
    "    def PFC_step(input_data, network_state):\n",
    "        with tf.variable_scope(\"PFC\", reuse=False):\n",
    "            return PFC_cell(inputs = input_data, state = network_state) \n",
    "\n",
    "    # Cue inputs\n",
    "\n",
    "    num_timesteps = 5\n",
    "    cue_timeseries = tf.placeholder(shape=[batch_size, num_timesteps, 1], dtype=tf.float32, name = 'cues_timeseries')\n",
    "\n",
    "    for t in range(num_timesteps):\n",
    "\n",
    "        current_cue = cue_timeseries[:,t]\n",
    "\n",
    "        PFC_state = PFC_step(input_data = current_cue, network_state = PFC_state_previous)\n",
    "        # The output from the PFC into the sensorymotor system will be what we were previously calling the cue variable\n",
    "        # We'll now call it the rule\n",
    "        PFC_output = tf.contrib.layers.fully_connected(PFC_state[0], 1, activation_fn = tf.nn.relu)\n",
    "\n",
    "        PFC_state_previous = PFC_state[1]\n",
    "\n",
    "    sess = tf.Session()\n",
    "\n",
    "    ct = np.reshape([np.random.rand() for k in range(num_timesteps * batch_size * num_batches)], [num_batches, batch_size, num_timesteps, 1])\n",
    "\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for b in range(num_batches):\n",
    "\n",
    "        ct_in = ct[b, :, :]\n",
    "\n",
    "        o = sess.run([PFC_output], feed_dict = {cue_timeseries:ct_in})\n",
    "\n",
    "        print o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 30.173136\n",
      "\n",
      "\n",
      "\n",
      "timestep 0\n",
      "out [[ 0.36920798  0.29209906]\n",
      " [ 0.39833575  0.35045677]\n",
      " [ 0.66161537  0.49645451]\n",
      " [ 0.34537029  0.97488409]\n",
      " [ 0.48821974  0.61642319]\n",
      " [ 0.84397435  0.80030334]\n",
      " [ 0.73653853  0.70231158]\n",
      " [ 0.60341281  0.40119025]\n",
      " [ 0.51318258  0.64798224]\n",
      " [ 0.60678029  0.42023078]\n",
      " [ 0.51748782  0.53996229]\n",
      " [ 0.6581943   0.09190799]\n",
      " [ 0.69590026  0.83129793]\n",
      " [ 0.18027602  0.76918507]\n",
      " [ 0.73741758  0.71632922]\n",
      " [ 0.41613352  0.76796395]] \n",
      "vis in [[ 0.30437766  0.05984119]\n",
      " [ 0.03827429  0.53086522]\n",
      " [ 0.75191231  0.36383864]\n",
      " [ 0.53246449  0.95325261]\n",
      " [ 0.67810023  0.49844057]\n",
      " [ 0.735082    0.99988543]\n",
      " [ 0.58651881  0.5719051 ]\n",
      " [ 0.26848585  0.62243138]\n",
      " [ 0.24958359  0.18605364]\n",
      " [ 0.32364831  0.71032497]\n",
      " [ 0.34088788  0.10132722]\n",
      " [ 0.57794601  0.01502526]\n",
      " [ 0.40495217  0.78298202]\n",
      " [ 0.11288273  0.69339695]\n",
      " [ 0.59219334  0.98023485]\n",
      " [ 0.23257895  0.78988141]] \n",
      "aud in [[ 0.29504544  0.40057098]\n",
      " [ 0.65732612  0.14152049]\n",
      " [ 0.43632055  0.55188496]\n",
      " [ 0.01789193  0.90311062]\n",
      " [ 0.15140816  0.6374227 ]\n",
      " [ 0.86632677  0.61224656]\n",
      " [ 0.77653268  0.77790314]\n",
      " [ 0.93903289  0.12086804]\n",
      " [ 0.64355641  0.98331188]\n",
      " [ 0.88765471  0.08335088]\n",
      " [ 0.55401449  0.85120639]\n",
      " [ 0.6283489   0.04622556]\n",
      " [ 0.89220252  0.84543173]\n",
      " [ 0.01387293  0.76098502]\n",
      " [ 0.79536873  0.46960102]\n",
      " [ 0.48671166  0.69099179]] \n",
      "rule chosen [1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0] \n",
      "correct rule [1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0]\n",
      "\n",
      "\n",
      "timestep 1\n",
      "out [[ 0.59579241  0.23591536]\n",
      " [ 0.66775858  0.82630908]\n",
      " [ 0.43009919  0.29169306]\n",
      " [ 0.30303025  0.08304827]\n",
      " [ 0.14089508  0.7049616 ]\n",
      " [ 0.22610185  0.29089615]\n",
      " [ 0.09619366  0.46296313]\n",
      " [ 0.19610651  0.27669576]\n",
      " [ 0.40301007  0.54278135]\n",
      " [ 0.33708242  0.55534208]\n",
      " [ 0.52644217  0.65055543]\n",
      " [ 0.53009206  0.42109188]\n",
      " [ 0.57318211  0.69076824]\n",
      " [ 0.77178562  0.39580399]\n",
      " [ 0.41742635  0.63503039]\n",
      " [ 0.38141462  0.38832596]] \n",
      "vis in [[ 0.68195802  0.41483872]\n",
      " [ 0.84652171  0.93124673]\n",
      " [ 0.95524569  0.35081112]\n",
      " [ 0.00687894  0.0101832 ]\n",
      " [ 0.07038548  0.59428011]\n",
      " [ 0.06133981  0.17497503]\n",
      " [ 0.07174315  0.40604844]\n",
      " [ 0.2987152   0.20617263]\n",
      " [ 0.71822062  0.84507493]\n",
      " [ 0.59326818  0.26658491]\n",
      " [ 0.29008546  0.30339092]\n",
      " [ 0.68121672  0.76789511]\n",
      " [ 0.87495459  0.76258397]\n",
      " [ 0.86727489  0.63720619]\n",
      " [ 0.62464854  0.64465171]\n",
      " [ 0.60741541  0.30509552]] \n",
      "aud in [[ 0.62061481  0.0432794 ]\n",
      " [ 0.61856332  0.77996877]\n",
      " [ 0.0254617   0.2271209 ]\n",
      " [ 0.67522098  0.14507091]\n",
      " [ 0.2723558   0.90897685]\n",
      " [ 0.46046434  0.40155884]\n",
      " [ 0.13455615  0.59611752]\n",
      " [ 0.13968981  0.42502228]\n",
      " [ 0.1941867   0.2341946 ]\n",
      " [ 0.1301154   0.96635817]\n",
      " [ 0.85992944  0.99933137]\n",
      " [ 0.47713551  0.07067368]\n",
      " [ 0.38415291  0.67790218]\n",
      " [ 0.81503491  0.12715635]\n",
      " [ 0.30563859  0.68753544]\n",
      " [ 0.21554966  0.562191  ]] \n",
      "rule chosen [2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0] \n",
      "correct rule [2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0]\n",
      "\n",
      "\n",
      "timestep 2\n",
      "out [[ 0.16609764  0.69448501]\n",
      " [ 0.65054083  0.05835778]\n",
      " [ 0.98002207  0.64632636]\n",
      " [ 0.80196059  0.90449327]\n",
      " [ 0.71158582  0.77633601]\n",
      " [ 0.61325324  0.46025097]\n",
      " [ 0.12358624  0.83617938]\n",
      " [ 0.56245899  0.45951214]\n",
      " [ 0.75930679  0.03257502]\n",
      " [ 0.36107022  0.78495729]\n",
      " [ 0.1366556   0.20588073]\n",
      " [ 0.48197353  0.59279591]\n",
      " [ 0.03108899  0.28096858]\n",
      " [ 0.8381778   0.64350384]\n",
      " [ 0.18322855  0.00689406]\n",
      " [ 0.2321893   0.44801617]] \n",
      "vis in [[ 0.15475629  0.7003414 ]\n",
      " [ 0.63176039  0.06594195]\n",
      " [ 0.25346763  0.07155823]\n",
      " [ 0.78646432  0.91441312]\n",
      " [ 0.02211443  0.03180034]\n",
      " [ 0.02047258  0.28310471]\n",
      " [ 0.73717585  0.86358313]\n",
      " [ 0.01208765  0.42613389]\n",
      " [ 0.83861107  0.00422554]\n",
      " [ 0.98378705  0.58611287]\n",
      " [ 0.13017957  0.20815193]\n",
      " [ 0.47139437  0.60071144]\n",
      " [ 0.01558099  0.28509518]\n",
      " [ 0.35625238  0.90004503]\n",
      " [ 0.67852797  0.77541456]\n",
      " [ 0.4365534   0.87491488]] \n",
      "aud in [[ 0.54685865  0.65833857]\n",
      " [ 0.935214    0.63465358]\n",
      " [ 0.97980028  0.66443941]\n",
      " [ 0.88834927  0.94223032]\n",
      " [ 0.71213649  0.78129645]\n",
      " [ 0.6139804   0.46929476]\n",
      " [ 0.12731469  0.8384045 ]\n",
      " [ 0.56098257  0.46059992]\n",
      " [ 0.04846474  0.98035066]\n",
      " [ 0.36564094  0.80259272]\n",
      " [ 0.196047    0.78767821]\n",
      " [ 0.38295506  0.33764446]\n",
      " [ 0.81393856  0.77548645]\n",
      " [ 0.83432286  0.64744113]\n",
      " [ 0.1835534   0.02021307]\n",
      " [ 0.23414475  0.45342246]] \n",
      "rule chosen [1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0] \n",
      "correct rule [1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0]\n",
      "\n",
      "\n",
      "timestep 3\n",
      "out [[ 0.57529938  0.40710661]\n",
      " [ 0.31358492  0.66386545]\n",
      " [ 0.03309346  0.57075232]\n",
      " [ 0.19382089  0.45925078]\n",
      " [ 0.91390169  0.29619879]\n",
      " [ 0.13566719  0.49006146]\n",
      " [ 0.30820364  0.97631508]\n",
      " [ 0.33505887  0.64805007]\n",
      " [ 0.59579718  0.8240931 ]\n",
      " [ 0.58649206  0.61695117]\n",
      " [ 0.62847883  0.76279831]\n",
      " [ 0.28190649  0.35674143]\n",
      " [ 0.26347041  0.52062279]\n",
      " [ 0.25365818  0.20167017]\n",
      " [ 0.14543669  0.67873073]\n",
      " [ 0.41651362  0.57090658]] \n",
      "vis in [[ 0.54880073  0.28536469]\n",
      " [ 0.56106261  0.68172524]\n",
      " [ 0.02439085  0.34526851]\n",
      " [ 0.0209441   0.79452556]\n",
      " [ 0.95676417  0.13398207]\n",
      " [ 0.16424317  0.09602602]\n",
      " [ 0.11511435  0.99439452]\n",
      " [ 0.18646516  0.69496126]\n",
      " [ 0.6843565   0.7262926 ]\n",
      " [ 0.78897219  0.55650435]\n",
      " [ 0.77497637  0.52757742]\n",
      " [ 0.56354962  0.25836995]\n",
      " [ 0.20487262  0.54049984]\n",
      " [ 0.24656309  0.3005765 ]\n",
      " [ 0.29367364  0.75909074]\n",
      " [ 0.40625047  0.63263699]] \n",
      "aud in [[ 0.70418574  0.47728091]\n",
      " [ 0.1596784   0.57141879]\n",
      " [ 0.05017901  0.89758017]\n",
      " [ 0.44310985  0.11327335]\n",
      " [ 0.95971688  0.36707575]\n",
      " [ 0.1961739   0.95993538]\n",
      " [ 0.68489611  0.99761794]\n",
      " [ 0.65836957  0.57759102]\n",
      " [ 0.70579448  0.85726111]\n",
      " [ 0.48918184  0.60137905]\n",
      " [ 0.66753923  0.95891248]\n",
      " [ 0.00843858  0.40815658]\n",
      " [ 0.44058779  0.47046407]\n",
      " [ 0.26075246  0.06589734]\n",
      " [ 0.10271751  0.52759473]\n",
      " [ 0.54751922  0.42971455]] \n",
      "rule chosen [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0] \n",
      "correct rule [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0]\n",
      "\n",
      "\n",
      "timestep 4\n",
      "out [[ 0.40471169  0.74862301]\n",
      " [ 0.24284646  0.47465599]\n",
      " [ 0.6240648   0.48071909]\n",
      " [ 0.71556741  0.29841867]\n",
      " [ 0.48453531  0.73414409]\n",
      " [ 0.61169744  0.7898199 ]\n",
      " [ 0.40797842  0.63934845]\n",
      " [ 0.65474004  0.64605761]\n",
      " [ 0.59897488  0.30482167]\n",
      " [ 0.85702258  0.62829465]\n",
      " [ 0.13723992  0.54126894]\n",
      " [ 0.50689399  0.58934468]\n",
      " [ 0.49764872  0.29830343]\n",
      " [ 0.70491475  0.40660697]\n",
      " [ 0.61747593  0.63488299]\n",
      " [ 0.94620937  0.28152609]] \n",
      "vis in [[ 0.59769557  0.57403961]\n",
      " [ 0.21516731  0.43567064]\n",
      " [ 0.45993628  0.09672936]\n",
      " [ 0.61036922  0.3984273 ]\n",
      " [ 0.81292862  0.57034835]\n",
      " [ 0.95634819  0.7497835 ]\n",
      " [ 0.43273142  0.76761482]\n",
      " [ 0.65671534  0.78303828]\n",
      " [ 0.69724509  0.00256644]\n",
      " [ 0.85475499  0.86672003]\n",
      " [ 0.17368437  0.12400105]\n",
      " [ 0.06073235  0.54932358]\n",
      " [ 0.21764568  0.35807807]\n",
      " [ 0.76333268  0.54717953]\n",
      " [ 0.907892    0.57125678]\n",
      " [ 0.92128416  0.21466967]] \n",
      "aud in [[ 0.19739107  0.83654639]\n",
      " [ 0.30888723  0.35719303]\n",
      " [ 0.78897666  0.72818257]\n",
      " [ 0.76557076  0.03767731]\n",
      " [ 0.12541204  0.85732087]\n",
      " [ 0.23672779  0.7479419 ]\n",
      " [ 0.43212009  0.26482219]\n",
      " [ 0.66861991  0.25053215]\n",
      " [ 0.46034844  0.50563062]\n",
      " [ 0.8632409   0.08371719]\n",
      " [ 0.06344633  0.98847279]\n",
      " [ 0.98638562  0.48067564]\n",
      " [ 0.74876886  0.14586019]\n",
      " [ 0.62731949  0.0237384 ]\n",
      " [ 0.27155957  0.58819293]\n",
      " [ 0.9138582   0.12156383]] \n",
      "rule chosen [1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0] \n",
      "correct rule [1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0]\n",
      "\n",
      "\n",
      "timestep 5\n",
      "out [[ 0.51767862  0.23459572]\n",
      " [ 0.33270332  0.39686441]\n",
      " [ 0.57177311  0.59550983]\n",
      " [ 0.7854315   0.38403222]\n",
      " [ 0.34235165  0.32554287]\n",
      " [ 0.28579807  0.52281374]\n",
      " [ 0.77519393  0.80848557]\n",
      " [ 0.5681693   0.72177249]\n",
      " [ 0.24929118  0.37103146]\n",
      " [ 0.65114605  0.23614302]\n",
      " [ 0.36160201  0.70702308]\n",
      " [ 0.03954209  0.78260195]\n",
      " [ 0.42693514  0.32728902]\n",
      " [ 0.65222734  0.12421296]\n",
      " [ 0.55986059  0.61155641]\n",
      " [ 0.58268851  0.32758814]] \n",
      "vis in [[ 0.21154151  0.0430089 ]\n",
      " [ 0.01236185  0.15924658]\n",
      " [ 0.46504181  0.78001556]\n",
      " [ 0.83857809  0.16075185]\n",
      " [ 0.16478305  0.09563218]\n",
      " [ 0.27302773  0.36533   ]\n",
      " [ 0.66571207  0.83243203]\n",
      " [ 0.45160327  0.90626011]\n",
      " [ 0.05528619  0.58302834]\n",
      " [ 0.43962173  0.20243924]\n",
      " [ 0.21056545  0.87843055]\n",
      " [ 0.00648674  0.77092986]\n",
      " [ 0.38825383  0.41791389]\n",
      " [ 0.43832715  0.01546821]\n",
      " [ 0.577383    0.60861667]\n",
      " [ 0.94901656  0.53284274]] \n",
      "aud in [[ 0.95231276  0.4772581 ]\n",
      " [ 0.79695626  0.75213903]\n",
      " [ 0.71464907  0.40563247]\n",
      " [ 0.68116542  0.69067689]\n",
      " [ 0.59201036  0.66155919]\n",
      " [ 0.31587579  0.7992139 ]\n",
      " [ 0.87731487  0.86358786]\n",
      " [ 0.72735997  0.5393431 ]\n",
      " [ 0.54920692  0.12757053]\n",
      " [ 0.94907844  0.27551681]\n",
      " [ 0.56251142  0.56523959]\n",
      " [ 0.15724234  0.86550674]\n",
      " [ 0.48505116  0.25939867]\n",
      " [ 0.99754314  0.19518088]\n",
      " [ 0.50857663  0.70247899]\n",
      " [ 0.02846093  0.12423731]] \n",
      "rule chosen [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0] \n",
      "correct rule [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0]\n",
      "\n",
      "\n",
      "timestep 6\n",
      "out [[ 0.61315036  0.26325452]\n",
      " [ 0.66617006  0.60031289]\n",
      " [ 0.61094332  0.61395901]\n",
      " [ 0.44806656  0.16292661]\n",
      " [ 0.67479682  0.32712436]\n",
      " [ 0.63095385  0.12328958]\n",
      " [ 0.09675939  0.1792597 ]\n",
      " [ 0.86926085  0.83812898]\n",
      " [ 0.84027272  0.60896921]\n",
      " [ 0.67997396  0.5326376 ]\n",
      " [ 0.53123593  0.28921142]\n",
      " [ 0.11084472  0.42317936]\n",
      " [ 0.54705906  0.33432353]\n",
      " [ 0.40292421  0.42688638]\n",
      " [ 0.09482025  0.64063072]\n",
      " [ 0.85722482  0.00129046]] \n",
      "vis in [[ 0.64624524  0.35113751]\n",
      " [ 0.7560628   0.4322076 ]\n",
      " [ 0.5063956   0.59786457]\n",
      " [ 0.29844941  0.39473714]\n",
      " [ 0.77725786  0.43931193]\n",
      " [ 0.79712352  0.28421049]\n",
      " [ 0.06539698  0.31371768]\n",
      " [ 0.85580221  0.97439635]\n",
      " [ 0.66740872  0.78195836]\n",
      " [ 0.92173424  0.81874322]\n",
      " [ 0.49453493  0.20240843]\n",
      " [ 0.0991967   0.20808789]\n",
      " [ 0.90645371  0.36328158]\n",
      " [ 0.67504122  0.8244234 ]\n",
      " [ 0.16869441  0.8484676 ]\n",
      " [ 0.78465828  0.04473022]] \n",
      "aud in [[ 0.49247178  0.32934217]\n",
      " [ 0.44068831  0.93453835]\n",
      " [ 0.70206859  0.74943214]\n",
      " [ 0.60203302  0.01529632]\n",
      " [ 0.47056224  0.38405003]\n",
      " [ 0.3858      0.07766282]\n",
      " [ 0.16627366  0.05421965]\n",
      " [ 0.80554958  0.84816703]\n",
      " [ 0.98272341  0.59143181]\n",
      " [ 0.35107167  0.38838631]\n",
      " [ 0.49854794  0.49926339]\n",
      " [ 0.13592424  0.74302098]\n",
      " [ 0.07086246  0.42918616]\n",
      " [ 0.10081939  0.10863688]\n",
      " [ 0.05878307  0.4540984 ]\n",
      " [ 0.85790203  0.13455382]] \n",
      "rule chosen [2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0] \n",
      "correct rule [2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0]\n",
      "\n",
      "\n",
      "timestep 7\n",
      "out [[ 0.47361532  0.30084422]\n",
      " [ 0.89653039  0.60995013]\n",
      " [ 0.70989192  0.03558408]\n",
      " [ 0.46982363  0.80599314]\n",
      " [ 0.40731347  0.92059541]\n",
      " [ 0.63383073  0.62224823]\n",
      " [ 0.12641217  0.21067485]\n",
      " [ 0.69819319  0.98135203]\n",
      " [ 0.13780753  0.69754827]\n",
      " [ 0.7543326   0.53924304]\n",
      " [ 0.8180663   0.35153437]\n",
      " [ 0.08164513  0.15301964]\n",
      " [ 0.5000788   0.50134319]\n",
      " [ 1.00578749  0.34053871]\n",
      " [ 0.37335935  0.27624875]\n",
      " [ 0.2000909   0.9854297 ]] \n",
      "vis in [[ 0.19746175  0.31388717]\n",
      " [ 0.6025824   0.34687727]\n",
      " [ 0.72711219  0.04813003]\n",
      " [ 0.89036715  0.32260397]\n",
      " [ 0.57816946  0.37976184]\n",
      " [ 0.63732329  0.6397859 ]\n",
      " [ 0.13655153  0.22327963]\n",
      " [ 0.69571536  0.99884959]\n",
      " [ 0.14733207  0.70684383]\n",
      " [ 0.50657714  0.40710145]\n",
      " [ 0.95944096  0.71376621]\n",
      " [ 0.09224673  0.16595065]\n",
      " [ 0.50286662  0.51921938]\n",
      " [ 0.59977324  0.01595923]\n",
      " [ 0.80345416  0.33115052]\n",
      " [ 0.76565124  0.75169261]] \n",
      "aud in [[ 0.44816815  0.27772236]\n",
      " [ 0.8661758   0.57323518]\n",
      " [ 0.66845673  0.3085913 ]\n",
      " [ 0.4400093   0.76961176]\n",
      " [ 0.37740408  0.88884599]\n",
      " [ 0.30085232  0.30670061]\n",
      " [ 0.55379926  0.65786957]\n",
      " [ 0.6531941   0.61514192]\n",
      " [ 0.60641661  0.09100501]\n",
      " [ 0.72538478  0.50374804]\n",
      " [ 0.77691273  0.3076222 ]\n",
      " [ 0.85012217  0.95060249]\n",
      " [ 0.75684556  0.98798498]\n",
      " [ 0.98730507  0.313478  ]\n",
      " [ 0.34736493  0.23836465]\n",
      " [ 0.16586942  0.94363322]] \n",
      "rule chosen [2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0] \n",
      "correct rule [2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0]\n",
      "\n",
      "\n",
      "timestep 8\n",
      "out [[ 0.18550447  0.96338034]\n",
      " [ 0.00738261  0.64872229]\n",
      " [ 0.93739045  0.35224962]\n",
      " [ 0.81267041  0.49457353]\n",
      " [ 0.35168689  0.55521232]\n",
      " [ 0.11040383  0.03373402]\n",
      " [ 0.45429331  0.6343751 ]\n",
      " [ 0.72470707  0.9365828 ]\n",
      " [ 0.22481871  0.89922845]\n",
      " [ 0.87871307  0.90201175]\n",
      " [ 0.31642893  0.98108613]\n",
      " [ 0.55527854  0.04048982]\n",
      " [ 0.6343196   0.8119967 ]\n",
      " [ 0.41364375  0.2246424 ]\n",
      " [ 0.77419358  0.5377028 ]\n",
      " [ 0.93833488  0.17446047]] \n",
      "vis in [[ 0.18324108  0.98589105]\n",
      " [ 0.00347366  0.66609425]\n",
      " [ 0.93947602  0.38326602]\n",
      " [ 0.25171724  0.30714791]\n",
      " [ 0.07314782  0.27895308]\n",
      " [ 0.0942213   0.005551  ]\n",
      " [ 0.45016362  0.65164198]\n",
      " [ 0.72260069  0.96753165]\n",
      " [ 0.26038008  0.76382782]\n",
      " [ 0.17980623  0.45633407]\n",
      " [ 0.42194856  0.50908728]\n",
      " [ 0.94107476  0.6915625 ]\n",
      " [ 0.88854812  0.26588001]\n",
      " [ 0.41407924  0.25070281]\n",
      " [ 0.65659674  0.98965243]\n",
      " [ 0.69089359  0.01063611]] \n",
      "aud in [[ 0.26375829  0.78060141]\n",
      " [ 0.64267357  0.53757772]\n",
      " [ 0.66990912  0.84008738]\n",
      " [ 0.8118539   0.4923219 ]\n",
      " [ 0.34286761  0.54849649]\n",
      " [ 0.58142521  0.86580875]\n",
      " [ 0.3588451   0.07468705]\n",
      " [ 0.92312495  0.51382086]\n",
      " [ 0.21950713  0.89811274]\n",
      " [ 0.88189213  0.90508703]\n",
      " [ 0.31677975  0.98115072]\n",
      " [ 0.55500005  0.03573206]\n",
      " [ 0.64341561  0.81069453]\n",
      " [ 0.35433851  0.9468425 ]\n",
      " [ 0.77847984  0.54324629]\n",
      " [ 0.94344891  0.17057669]] \n",
      "rule chosen [1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0] \n",
      "correct rule [1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0]\n",
      "\n",
      "\n",
      "timestep 9\n",
      "out [[ 0.44210774  0.13501096]\n",
      " [ 0.44979703  0.50242394]\n",
      " [ 1.02851474  0.43294546]\n",
      " [ 0.77698463  0.42869532]\n",
      " [ 0.75719404  0.1239626 ]\n",
      " [ 0.78317815  0.4341104 ]\n",
      " [ 0.43136847  0.46885595]\n",
      " [ 0.8444097   0.65081626]\n",
      " [ 0.52480471  0.46109122]\n",
      " [ 0.35160738  0.70683622]\n",
      " [ 0.49831361  0.37120119]\n",
      " [ 0.69494033  0.83943552]\n",
      " [ 0.82894903  0.40642393]\n",
      " [ 0.1985202   0.27865791]\n",
      " [ 0.42214936  0.3630031 ]\n",
      " [ 0.29036283  0.2904948 ]] \n",
      "vis in [[ 0.37860966  0.16448574]\n",
      " [ 0.45288299  0.63776405]\n",
      " [ 0.90677937  0.71944641]\n",
      " [ 0.81619414  0.05861615]\n",
      " [ 0.40319075  0.14444251]\n",
      " [ 0.34887105  0.82881927]\n",
      " [ 0.04551713  0.42467716]\n",
      " [ 0.54083046  0.241308  ]\n",
      " [ 0.42975438  0.24335804]\n",
      " [ 0.01665719  0.84351546]\n",
      " [ 0.47411849  0.84369726]\n",
      " [ 0.60488343  0.85204646]\n",
      " [ 0.62139382  0.54026016]\n",
      " [ 0.35131854  0.55373334]\n",
      " [ 0.78114194  0.62413043]\n",
      " [ 0.46755947  0.89052748]] \n",
      "aud in [[ 0.41244087  0.13353722]\n",
      " [ 0.37488611  0.46286741]\n",
      " [ 0.95029835  0.355716  ]\n",
      " [ 0.69440582  0.6140982 ]\n",
      " [ 0.89042732  0.09824139]\n",
      " [ 0.89260879  0.33215021]\n",
      " [ 0.61096506  0.53270822]\n",
      " [ 0.94913021  0.89775636]\n",
      " [ 0.52821691  0.58610339]\n",
      " [ 0.53525709  0.67834629]\n",
      " [ 0.40249322  0.18352944]\n",
      " [ 0.65960247  0.88374428]\n",
      " [ 0.83188817  0.39667453]\n",
      " [ 0.05121653  0.14586001]\n",
      " [ 0.1366164   0.22489377]\n",
      " [ 0.09228776  0.01755222]] \n",
      "rule chosen [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0] \n",
      "correct rule [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEKCAYAAAD0Luk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noamvZU5MeQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13d1190d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we will create a mapping from cues to rules\n",
    "# The rule associated with each cue will change with time and a RNN will have to learn and remember the recent mapping\n",
    "# while not hanging onto it too long as the mapping changes\n",
    "\n",
    "# Define an RNN representing the PFC\n",
    "\n",
    "num_units_PFC = 20\n",
    "\n",
    "PFC_cell = tf.contrib.rnn.LSTMBlockCell(num_units = num_units_PFC)\n",
    "PFC_state_previous = PFC_cell.zero_state(batch_size, tf.float32) # Initial state of PFC\n",
    "\n",
    "# This does one cycle of the RNN\n",
    "def PFC_step(input_data, network_state):\n",
    "    with tf.variable_scope(\"PFC\", reuse=False):\n",
    "        return PFC_cell(inputs = input_data, state = network_state) \n",
    "    \n",
    "# Cue inputs\n",
    "\n",
    "num_timesteps = 10\n",
    "cue_timeseries = tf.placeholder(shape=[batch_size, num_timesteps, 1], dtype=tf.float32, name = 'cues_timeseries')\n",
    "\n",
    "input_vis = tf.placeholder(shape=[batch_size, num_timesteps, 2], dtype=tf.float32, name = 'input_vis')\n",
    "input_aud = tf.placeholder(shape=[batch_size, num_timesteps, 2], dtype=tf.float32, name = 'input_aud')\n",
    "\n",
    "def rvis():\n",
    "    return 1.0\n",
    "def raud():\n",
    "    return 2.0\n",
    "def rnull():\n",
    "    return 0.0\n",
    "\n",
    "def cue_to_rule_mapping_function(t, integer_input): # Define a changing mapping from cues to rules\n",
    "    \n",
    "    if t % 10 < 5: # Always true here but we'll make this change later -- we can use this to set up time-dependent cue-to-rule mappings\n",
    "        r1 = tf.cond(tf.equal(integer_input, tf.constant(0, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "    \n",
    "        r2 = tf.cond(tf.equal(integer_input, tf.constant(1, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "        \n",
    "        r3 = tf.cond(tf.equal(integer_input, tf.constant(2, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "        \n",
    "        r4 = tf.cond(tf.equal(integer_input, tf.constant(3, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "    else: # We can use this to set up time-dependent cue-to-rule mappings\n",
    "        r1 = tf.cond(tf.equal(integer_input, tf.constant(0, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "    \n",
    "        r2 = tf.cond(tf.equal(integer_input, tf.constant(1, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "        \n",
    "        r3 = tf.cond(tf.equal(integer_input, tf.constant(2, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "        \n",
    "        r4 = tf.cond(tf.equal(integer_input, tf.constant(3, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "        \n",
    "    return tf.reduce_max([r1,r2,r3,r4])\n",
    "\n",
    "loss = 0\n",
    "\n",
    "outs = []\n",
    "\n",
    "rules_chosen = []\n",
    "\n",
    "for t in range(num_timesteps):\n",
    "\n",
    "    current_cue = cue_timeseries[:,t]\n",
    "\n",
    "    PFC_state = PFC_step(input_data = current_cue, network_state = PFC_state_previous)\n",
    "    # The output from the PFC into the sensorymotor system will be what we were previously calling the cue variable\n",
    "    # We'll now call it the rule\n",
    "    PFC_output = tf.contrib.layers.fully_connected(PFC_state[0], 1, activation_fn = tf.nn.relu)\n",
    "    \n",
    "    input_cue_to_sm_sys = PFC_output\n",
    "    input_total = tf.concat([input_vis[:,t], input_aud[:,t], input_cue_to_sm_sys], axis = -1)\n",
    "    \n",
    "    num_hidden_sensorymotor = 20\n",
    "    hidden_sensorymotor = tf.contrib.layers.fully_connected(input_total, num_hidden_sensorymotor, activation_fn = tf.nn.relu)\n",
    "    num_out_sensorymotor = 2\n",
    "    out_sensorymotor = tf.contrib.layers.fully_connected(hidden_sensorymotor, num_out_sensorymotor, activation_fn = tf.nn.relu)\n",
    "    \n",
    "    PFC_state_previous = PFC_state[1]\n",
    "    \n",
    "    rul_chose = []\n",
    "    for e in range(batch_size):\n",
    "        cc = current_cue[e][0]\n",
    "        cue_to_rule_mapping_function_output = cue_to_rule_mapping_function(t, cc)\n",
    "        if t>=0: # Always true here but we'll make this change later -- we can use this to set up time-dependent loss functions, e.g., only look at late times\n",
    "            loss_contrib = tf.cond(tf.equal(cue_to_rule_mapping_function_output, tf.constant(1, dtype = tf.float32)), true_fn = lambda: tf.norm(input_vis[e,t] - out_sensorymotor[e]),  false_fn = lambda: tf.norm(input_aud[e,t] - out_sensorymotor[e]))\n",
    "            loss += loss_contrib\n",
    "        rul_chose.append(cue_to_rule_mapping_function_output)\n",
    "    rules_chosen.append(rul_chose)\n",
    "\n",
    "    outs.append(out_sensorymotor)\n",
    "        \n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op=optimizer.minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Random cue\n",
    "ct = np.reshape([np.random.randint(0,4) for k in range(num_timesteps * batch_size * num_batches)], [num_batches, batch_size, num_timesteps, 1])\n",
    "    \n",
    "in_vis_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_timesteps * batch_size * num_batches)] \n",
    "in_vis_list = np.reshape(in_vis_list_unshaped, [num_batches,batch_size,num_timesteps, 2])\n",
    "\n",
    "in_aud_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_timesteps * batch_size * num_batches)]\n",
    "in_aud_list = np.reshape(in_aud_list_unshaped, [num_batches,batch_size,num_timesteps, 2])\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "losses = []\n",
    "\n",
    "for b in range(num_batches): # Just testing\n",
    "        \n",
    "    ct_in = ct[b, :, :]\n",
    "\n",
    "    in_v = in_vis_list[b, :, :]\n",
    "\n",
    "    in_a = in_aud_list[b, :, :]\n",
    "\n",
    "    os, l, rc, _ = sess.run([outs, loss, rules_chosen, train_op], feed_dict = {cue_timeseries:ct_in, input_vis: in_v, input_aud:in_a})\n",
    "    # The outputs here are just for the last batch...\n",
    "    losses.append(l)\n",
    "    \n",
    "print \"Loss: %f\" %l\n",
    "print \"\\n\\n\"\n",
    "for q in range(num_timesteps):\n",
    "    print \"timestep %i\" % q\n",
    "    print \"out\", os[:][q], \"\\n\", \"vis in\", in_v[:,q],\"\\n\", \"aud in\", in_a[:, q],\"\\n\", \"rule chosen\", rc[:][q],\"\\n\", \"correct rule\", [sess.run(cue_to_rule_mapping_function(q, float(ct_in[e,q]))) for e in range(batch_size)]  \n",
    "    print \"\\n\"\n",
    "        \n",
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.title(\"Loss versus # batches\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
