{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This has just a PFC and sensory-motor system only, with the PFC as a LSTM. Does not have an MD yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammarblestone/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters of the network\n",
    "num_units_PFC = 30\n",
    "num_hidden_sensorymotor = 20\n",
    "num_timesteps = 12\n",
    "\n",
    "# Parameters of the training\n",
    "batch_size = 8\n",
    "num_batches = 2000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEFINITION OF THE TASK\n",
    "\n",
    "# The \"rule input\" to the sensory motor system, coming from PFC, currently takes the form of just a number, either 1.0 or 2.0\n",
    "# 1.0 indicates to use vision and ignore audition, and 2.0 indicates to use audition and ignore vision\n",
    "def rvis(): \n",
    "    return 1.0 # If the input to the sensory-motor system, x, has 1 <= x < 2 then use vision\n",
    "def raud(): # If the input to the sensory-motor system, x, has x > 2 then use audition\n",
    "    return 2.0\n",
    "def rnull():\n",
    "    return 0.0\n",
    "\n",
    "# This is the function that will be used to evaluate whether the PFC output the correct rule for a given cue, and to train it to do so\n",
    "def cue_to_rule_mapping_function(t, integer_input): # Define a changing mapping from cues to rules\n",
    "    \n",
    "    if t % 10 < 5: # We can use this type of conditioning to set up time-dependent cue-to-rule mappings\n",
    "        r1 = tf.cond(tf.equal(integer_input, tf.constant(0, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "    \n",
    "        r2 = tf.cond(tf.equal(integer_input, tf.constant(1, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "        \n",
    "        r3 = tf.cond(tf.equal(integer_input, tf.constant(2, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "        \n",
    "        r4 = tf.cond(tf.equal(integer_input, tf.constant(3, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "        \n",
    "    else: # We can use this type of conditioning to set up time-dependent cue-to-rule mappings\n",
    "        r1 = tf.cond(tf.equal(integer_input, tf.constant(0, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "    \n",
    "        r2 = tf.cond(tf.equal(integer_input, tf.constant(1, dtype = tf.float32)), true_fn = raud, false_fn = rnull)\n",
    "        \n",
    "        r3 = tf.cond(tf.equal(integer_input, tf.constant(2, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "        \n",
    "        r4 = tf.cond(tf.equal(integer_input, tf.constant(3, dtype = tf.float32)), true_fn = rvis, false_fn = rnull)\n",
    "        \n",
    "    return tf.reduce_max([r1,r2,r3,r4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for evaluating correctness\n",
    "def correctness(q, o, ina, inv, ctin): # Arguments: time, PFC output list, auditory input list, vision input list, cue inputs timeline\n",
    "    c = []\n",
    "    for e in range(batch_size):\n",
    "        if (np.linalg.norm(inv[e,q] - o[q][e]) < np.linalg.norm(ina[e,q] - o[q][e]) and sess.run(cue_to_rule_mapping_function(q, float(ctin[e,q]))) == 1.0):\n",
    "            c.append(\"correct\") # If the output coordinates are closer to the vision target than the auditory target and that's the right rule\n",
    "        elif (np.linalg.norm(inv[e,q] - o[q][e]) > np.linalg.norm(ina[e,q] - o[q][e]) and sess.run(cue_to_rule_mapping_function(q, float(ctin[e,q]))) == 2.0):\n",
    "            c.append(\"correct\") # If the output coordinates are closer to the auditory target than the vision target and that's the right rule\n",
    "        else:\n",
    "            c.append(\"incorrect\")\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.000517\n",
      "\n",
      "\n",
      "\n",
      "timestep 0\n",
      "out [[ 0.1988425   0.11831765]\n",
      " [ 0.00110585  0.12040298]\n",
      " [ 0.85094047  0.19506787]\n",
      " [ 0.6933794   0.74106205]\n",
      " [ 0.93259609  0.24449627]\n",
      " [ 0.48568058  0.22907554]\n",
      " [ 0.91558141  0.45905846]\n",
      " [ 0.26221672  0.95454204]] \n",
      "vis in [[  4.08802325e-01   5.73462557e-01]\n",
      " [  3.78790455e-04   1.20368496e-01]\n",
      " [  6.79744331e-01   3.29686321e-01]\n",
      " [  7.24733803e-02   1.86018705e-01]\n",
      " [  9.31802583e-01   2.44386170e-01]\n",
      " [  4.85164643e-01   2.28954120e-01]\n",
      " [  3.62704139e-01   5.87769967e-01]\n",
      " [  2.61325238e-01   9.54262455e-01]] \n",
      "aud in [[ 0.19900113  0.11785383]\n",
      " [ 0.60024819  0.68403697]\n",
      " [ 0.85109411  0.19420135]\n",
      " [ 0.69340123  0.7403544 ]\n",
      " [ 0.6536693   0.03733131]\n",
      " [ 0.36246441  0.20507452]\n",
      " [ 0.91556532  0.45831393]\n",
      " [ 0.60416138  0.15886799]] \n",
      "rule chosen [[-0.68249691]\n",
      " [ 0.36108354]\n",
      " [-1.14296782]\n",
      " [-0.68249691]\n",
      " [ 1.43990684]\n",
      " [ 0.36108354]\n",
      " [-0.68249691]\n",
      " [ 1.43990684]] \n",
      "correct rule [2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 1\n",
      "out [[ 0.23459661  0.42534465]\n",
      " [ 0.65964162  0.13029538]\n",
      " [ 0.4378897   0.38517636]\n",
      " [ 0.86868608  0.91496992]\n",
      " [ 0.12968752  0.88881576]\n",
      " [ 0.76142079  0.92993975]\n",
      " [ 0.90417159  0.21553929]\n",
      " [ 0.43501174  0.30566961]] \n",
      "vis in [[ 0.78355144  0.65881415]\n",
      " [ 0.65845861  0.13034546]\n",
      " [ 0.43715483  0.38501597]\n",
      " [ 0.8679288   0.91469689]\n",
      " [ 0.49764501  0.31846651]\n",
      " [ 0.25301232  0.96436113]\n",
      " [ 0.21053641  0.53995316]\n",
      " [ 0.05844978  0.42997065]] \n",
      "aud in [[ 0.2348677   0.42457961]\n",
      " [ 0.76795004  0.84152092]\n",
      " [ 0.71157436  0.11820647]\n",
      " [ 0.3014432   0.03862483]\n",
      " [ 0.1299319   0.88804342]\n",
      " [ 0.76156125  0.92894691]\n",
      " [ 0.90438737  0.21461499]\n",
      " [ 0.43509869  0.30515396]] \n",
      "rule chosen [[-0.8593365 ]\n",
      " [ 2.16132641]\n",
      " [ 0.42287442]\n",
      " [ 0.42097139]\n",
      " [-0.7192173 ]\n",
      " [-0.83771968]\n",
      " [-1.40157056]\n",
      " [-0.7192173 ]] \n",
      "correct rule [2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 2\n",
      "out [[ 0.38675705  0.34854692]\n",
      " [ 0.82062697  0.26188821]\n",
      " [ 0.28230071  0.34322491]\n",
      " [ 0.66742492  0.93059593]\n",
      " [ 0.28212491  0.93388152]\n",
      " [ 0.47250986  0.97948116]\n",
      " [ 0.56934351  0.87444746]\n",
      " [ 0.00982121  0.94345105]] \n",
      "vis in [[ 0.38615954  0.34841967]\n",
      " [ 0.81990416  0.26183992]\n",
      " [ 0.24860073  0.69668407]\n",
      " [ 0.20905935  0.40477184]\n",
      " [ 0.0642486   0.61037611]\n",
      " [ 0.27213505  0.87472352]\n",
      " [ 0.16564799  0.61882002]\n",
      " [ 0.86429778  0.41319831]] \n",
      "aud in [[ 0.34205406  0.34012978]\n",
      " [ 0.22139968  0.55793635]\n",
      " [ 0.28270513  0.34236362]\n",
      " [ 0.6675373   0.92971003]\n",
      " [ 0.282559    0.9328274 ]\n",
      " [ 0.47271944  0.97854754]\n",
      " [ 0.56948729  0.87359415]\n",
      " [ 0.01037583  0.94230113]] \n",
      "rule chosen [[ 0.60547638]\n",
      " [ 0.53677285]\n",
      " [-1.37625945]\n",
      " [-0.80091751]\n",
      " [-1.37518084]\n",
      " [-0.80727017]\n",
      " [-0.79284203]\n",
      " [-1.37518084]] \n",
      "correct rule [1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 3\n",
      "out [[ 0.9209305   0.12943278]\n",
      " [ 0.93939316  0.29402083]\n",
      " [ 0.14468032  0.10289072]\n",
      " [ 0.55913311  0.80240738]\n",
      " [ 0.11164448  0.14625897]\n",
      " [ 0.79187489  0.6054402 ]\n",
      " [ 0.3372494   0.87102616]\n",
      " [ 0.85451549  0.27995145]] \n",
      "vis in [[ 0.00554833  0.61272081]\n",
      " [ 0.05875342  0.68724841]\n",
      " [ 0.14442367  0.10276497]\n",
      " [ 0.74074703  0.14354946]\n",
      " [ 0.48708373  0.67479387]\n",
      " [ 0.58520133  0.13935893]\n",
      " [ 0.37106094  0.60208992]\n",
      " [ 0.85369315  0.27984771]] \n",
      "aud in [[ 0.92116206  0.12853067]\n",
      " [ 0.9396188   0.2930559 ]\n",
      " [ 0.11553048  0.1255616 ]\n",
      " [ 0.55953542  0.80120833]\n",
      " [ 0.11213544  0.14541741]\n",
      " [ 0.79195979  0.60458005]\n",
      " [ 0.33749653  0.87014999]\n",
      " [ 0.66766854  0.17207581]] \n",
      "rule chosen [[-1.50356412]\n",
      " [-1.44030535]\n",
      " [ 2.14315224]\n",
      " [-1.48494768]\n",
      " [-1.48475456]\n",
      " [-0.87059331]\n",
      " [-0.86198211]\n",
      " [ 0.56541932]] \n",
      "correct rule [2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 4\n",
      "out [[ 0.71487921  0.26487523]\n",
      " [ 0.02819954  0.15108083]\n",
      " [ 0.96943271  0.03926919]\n",
      " [ 0.15149224  0.7597363 ]\n",
      " [ 0.96694857  0.47144932]\n",
      " [ 0.80848712  0.54997921]\n",
      " [ 0.72365046  0.45430553]\n",
      " [ 0.05359669  0.91412026]] \n",
      "vis in [[ 0.71406449  0.26477883]\n",
      " [ 0.99557553  0.10377823]\n",
      " [ 0.79546641  0.317096  ]\n",
      " [ 0.15047468  0.75958418]\n",
      " [ 0.55796615  0.38399947]\n",
      " [ 0.8073459   0.54988088]\n",
      " [ 0.72278262  0.45418062]\n",
      " [ 0.38965552  0.46523822]] \n",
      "aud in [[ 0.65002504  0.22760603]\n",
      " [ 0.02849477  0.15047357]\n",
      " [ 0.96968925  0.03824631]\n",
      " [ 0.58486417  0.72418427]\n",
      " [ 0.9672358   0.47028491]\n",
      " [ 0.73918821  0.49896149]\n",
      " [ 0.58550028  0.32421681]\n",
      " [ 0.05393393  0.91327841]] \n",
      "rule chosen [[ 1.04072201]\n",
      " [-0.89081705]\n",
      " [-1.53062832]\n",
      " [ 0.41969872]\n",
      " [-1.54891086]\n",
      " [ 1.09691   ]\n",
      " [ 0.41510007]\n",
      " [-0.90295649]] \n",
      "correct rule [1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 5\n",
      "out [[ 0.70757806  0.98477513]\n",
      " [ 0.88675994  0.98071885]\n",
      " [ 0.9466573   0.49532419]\n",
      " [ 0.81323332  0.3824715 ]\n",
      " [ 0.1421538   0.02227621]\n",
      " [ 0.88206774  0.78026891]\n",
      " [ 0.33725241  0.85948223]\n",
      " [ 0.11592278  0.40534407]] \n",
      "vis in [[ 0.70627392  0.98457029]\n",
      " [ 0.31850762  0.90333572]\n",
      " [ 0.81612538  0.63694518]\n",
      " [ 0.81239839  0.38239018]\n",
      " [ 0.14142472  0.02228892]\n",
      " [ 0.76999116  0.39955314]\n",
      " [ 0.33664813  0.85921405]\n",
      " [ 0.11529975  0.40515324]] \n",
      "aud in [[ 0.8796662   0.44607754]\n",
      " [ 0.88713238  0.97935291]\n",
      " [ 0.94671037  0.49440853]\n",
      " [ 0.39895434  0.48686576]\n",
      " [ 0.47587284  0.78901215]\n",
      " [ 0.88212519  0.77930782]\n",
      " [ 0.16962495  0.18093259]\n",
      " [ 0.69667716  0.0847049 ]] \n",
      "rule chosen [[ 0.46769646]\n",
      " [-1.55548525]\n",
      " [-0.79024327]\n",
      " [ 0.44301045]\n",
      " [ 0.85184824]\n",
      " [-0.74076176]\n",
      " [ 1.09842134]\n",
      " [ 0.41086698]] \n",
      "correct rule [1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 6\n",
      "out [[ 0.48851621  0.18860772]\n",
      " [ 0.06253076  0.42669338]\n",
      " [ 0.78580511  0.64909536]\n",
      " [ 0.40966591  0.8792451 ]\n",
      " [ 0.08495551  0.24231748]\n",
      " [ 0.14568204  0.26482534]\n",
      " [ 0.76881766  0.15744357]\n",
      " [ 0.62094891  0.78725153]] \n",
      "vis in [[ 0.87210458  0.39365711]\n",
      " [ 0.87884918  0.89580528]\n",
      " [ 0.91717186  0.75749795]\n",
      " [ 0.55987236  0.14077647]\n",
      " [ 0.76127139  0.10415168]\n",
      " [ 0.14539195  0.26464962]\n",
      " [ 0.31421917  0.02253747]\n",
      " [ 0.1906192   0.50928827]] \n",
      "aud in [[ 0.48875597  0.1878111 ]\n",
      " [ 0.06292457  0.42585419]\n",
      " [ 0.7864577   0.64747501]\n",
      " [ 0.40994489  0.87827726]\n",
      " [ 0.08570791  0.24112461]\n",
      " [ 0.18514043  0.0515833 ]\n",
      " [ 0.76935388  0.15622345]\n",
      " [ 0.62160337  0.78577567]] \n",
      "rule chosen [[-1.05335426]\n",
      " [-1.00089896]\n",
      " [-2.2303741 ]\n",
      " [-1.05104589]\n",
      " [-2.20972395]\n",
      " [ 1.42128551]\n",
      " [-2.26304317]\n",
      " [-2.26496911]] \n",
      "correct rule [2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 7\n",
      "out [[ 0.14151299  0.80090857]\n",
      " [ 0.63262939  0.23754603]\n",
      " [ 0.80651736  0.02401516]\n",
      " [ 0.90502477  0.97933447]\n",
      " [ 0.04450709  0.84370351]\n",
      " [ 0.11892395  0.77702993]\n",
      " [ 0.77357388  0.31879461]\n",
      " [ 0.5596202   0.82361674]] \n",
      "vis in [[ 0.14037173  0.80073517]\n",
      " [ 0.36634508  0.78525071]\n",
      " [ 0.82658444  0.47403364]\n",
      " [ 0.90337493  0.97923531]\n",
      " [ 0.0435428   0.84346556]\n",
      " [ 0.36925694  0.51581971]\n",
      " [ 0.7725894   0.31867602]\n",
      " [ 0.61581182  0.63359909]] \n",
      "aud in [[ 0.84679521  0.59452366]\n",
      " [ 0.63276185  0.2368386 ]\n",
      " [ 0.8065897   0.02330191]\n",
      " [ 0.88673     0.9199764 ]\n",
      " [ 0.76519464  0.30392496]\n",
      " [ 0.11922605  0.77623853]\n",
      " [ 0.9588126   0.07107964]\n",
      " [ 0.56029248  0.82208426]] \n",
      "rule chosen [[ 0.74715531]\n",
      " [-0.8851099 ]\n",
      " [-0.87058222]\n",
      " [ 1.53050411]\n",
      " [ 1.49185693]\n",
      " [-0.88272512]\n",
      " [ 1.50729692]\n",
      " [-2.15283871]] \n",
      "correct rule [1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 8\n",
      "out [[ 0.06378359  0.44928575]\n",
      " [ 0.19440126  0.31323653]\n",
      " [ 0.12375143  0.81823444]\n",
      " [ 0.49856615  0.88392901]\n",
      " [ 0.34285015  0.79831886]\n",
      " [ 0.88248837  0.99217737]\n",
      " [ 0.62306827  0.56024098]\n",
      " [ 0.60206461  0.20101307]] \n",
      "vis in [[ 0.00791171  0.26522467]\n",
      " [ 0.91338783  0.27151443]\n",
      " [ 0.96640486  0.3043023 ]\n",
      " [ 0.49745005  0.88378307]\n",
      " [ 0.35258901  0.09804469]\n",
      " [ 0.88121282  0.99196206]\n",
      " [ 0.98708655  0.15314948]\n",
      " [ 0.13546184  0.25345252]] \n",
      "aud in [[ 0.06447194  0.44820893]\n",
      " [ 0.19463495  0.31256844]\n",
      " [ 0.12405042  0.81736184]\n",
      " [ 0.38016032  0.77599518]\n",
      " [ 0.34349734  0.79699233]\n",
      " [ 0.81219012  0.33558279]\n",
      " [ 0.62366341  0.55881577]\n",
      " [ 0.60259052  0.19989944]] \n",
      "rule chosen [[-2.08798361]\n",
      " [-0.79787028]\n",
      " [-0.79147971]\n",
      " [ 1.65748119]\n",
      " [-2.07381535]\n",
      " [ 0.83770967]\n",
      " [-2.06655622]\n",
      " [-2.08952475]] \n",
      "correct rule [2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 9\n",
      "out [[ 0.18605986  0.74512374]\n",
      " [ 0.24509674  0.50917953]\n",
      " [ 0.70967162  0.42417425]\n",
      " [ 0.40277636  0.34164512]\n",
      " [ 0.59835505  0.95859963]\n",
      " [ 0.10580024  0.6396836 ]\n",
      " [ 0.04399407  0.46722752]\n",
      " [ 0.99880815  0.96561551]] \n",
      "vis in [[ 0.18527411  0.74487484]\n",
      " [ 0.38529372  0.04303269]\n",
      " [ 0.7093283   0.42398318]\n",
      " [ 0.84103055  0.72322089]\n",
      " [ 0.59778863  0.95830563]\n",
      " [ 0.12939879  0.93301851]\n",
      " [ 0.20816417  0.49590029]\n",
      " [ 0.81204975  0.89219136]] \n",
      "aud in [[ 0.68363439  0.1364649 ]\n",
      " [ 0.24562339  0.50814017]\n",
      " [ 0.00240244  0.03412771]\n",
      " [ 0.40336551  0.34041782]\n",
      " [ 0.00946108  0.10398957]\n",
      " [ 0.10607787  0.63898997]\n",
      " [ 0.04457901  0.4662499 ]\n",
      " [ 0.99924056  0.96405776]] \n",
      "rule chosen [[ 0.41403803]\n",
      " [-1.73833275]\n",
      " [ 0.40646559]\n",
      " [-1.85430562]\n",
      " [ 0.85290182]\n",
      " [-0.80650771]\n",
      " [-1.70460689]\n",
      " [-1.7145716 ]] \n",
      "correct rule [1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 10\n",
      "out [[ 0.59513909  0.21021351]\n",
      " [ 0.06170768  0.71873879]\n",
      " [ 0.83396947  0.19267569]\n",
      " [ 0.1407126   0.91513002]\n",
      " [ 0.79097611  0.00817607]\n",
      " [ 0.86678129  0.97873807]\n",
      " [ 0.17704245  0.52254456]\n",
      " [ 0.8944093   0.47070479]] \n",
      "vis in [[ 0.3661829   0.84143631]\n",
      " [ 0.98116391  0.36250839]\n",
      " [ 0.32959598  0.55644828]\n",
      " [ 0.72387173  0.42198501]\n",
      " [ 0.790204    0.0082381 ]\n",
      " [ 0.86524524  0.97858592]\n",
      " [ 0.17634769  0.52237821]\n",
      " [ 0.89384497  0.47056374]] \n",
      "aud in [[ 0.59540981  0.20936528]\n",
      " [ 0.06199169  0.71794561]\n",
      " [ 0.83394414  0.19207457]\n",
      " [ 0.1411741   0.91404769]\n",
      " [ 0.15512168  0.87017852]\n",
      " [ 0.99318982  0.64028612]\n",
      " [ 0.47888156  0.38135025]\n",
      " [ 0.03095956  0.30204075]] \n",
      "rule chosen [[-1.2306658 ]\n",
      " [-0.71211326]\n",
      " [-0.66741323]\n",
      " [-1.25299811]\n",
      " [ 1.30309689]\n",
      " [ 0.90959525]\n",
      " [ 0.32975605]\n",
      " [ 0.35096872]] \n",
      "correct rule [2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n",
      "timestep 11\n",
      "out [[ 0.01817879  0.34701884]\n",
      " [ 0.16413054  0.40617287]\n",
      " [ 0.95498705  0.90894359]\n",
      " [ 0.64191771  0.95011675]\n",
      " [ 0.8702873   0.19968197]\n",
      " [ 0.29703385  0.4712615 ]\n",
      " [ 0.53034806  0.44657779]\n",
      " [ 0.29524672  0.69021362]] \n",
      "vis in [[ 0.06081886  0.20254153]\n",
      " [ 0.38819569  0.41384367]\n",
      " [ 0.26870603  0.01585933]\n",
      " [ 0.64077984  0.94997604]\n",
      " [ 0.00804686  0.94580619]\n",
      " [ 0.29640248  0.47115177]\n",
      " [ 0.52933927  0.44655335]\n",
      " [ 0.98739123  0.41597825]] \n",
      "aud in [[ 0.01865742  0.34624894]\n",
      " [ 0.16440483  0.40550569]\n",
      " [ 0.95524527  0.90773331]\n",
      " [ 0.21739903  0.84304194]\n",
      " [ 0.88792529  0.18926451]\n",
      " [ 0.11229329  0.66032161]\n",
      " [ 0.29261852  0.93101322]\n",
      " [ 0.29554212  0.689285  ]] \n",
      "rule chosen [[-1.50395799]\n",
      " [-0.94051039]\n",
      " [-1.48417866]\n",
      " [ 2.18723178]\n",
      " [-0.71287954]\n",
      " [ 0.49910679]\n",
      " [ 2.09655643]\n",
      " [-0.91753614]] \n",
      "correct rule [2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0]\n",
      "correctness: ['correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct', 'correct']\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13752bad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the network\n",
    "\n",
    "DO_SHARE = None # This is needed for the recurrency of the RNN, see: https://blog.evjang.com/2016/06/understanding-and-implementing.html\n",
    "\n",
    "PFC_state_previous = tf.contrib.rnn.LSTMBlockCell(num_units = num_units_PFC).zero_state(batch_size, tf.float32) # Initial state of PFC\n",
    "\n",
    "# This does one cycle of the PFC RNN\n",
    "def PFC_step(input_data, network_state):\n",
    "    with tf.variable_scope(\"PFC\", reuse=DO_SHARE):\n",
    "        PFC_cell = tf.contrib.rnn.LSTMBlockCell(num_units = num_units_PFC)\n",
    "        return PFC_cell(inputs = input_data, state = network_state) \n",
    "    \n",
    "# Cue inputs delivered INTO the PFC, e.g., high pass noise, UV light, and so forth, here defined currently as just an integer indiciating which cue\n",
    "cue_timeseries = tf.placeholder(shape=[batch_size, num_timesteps, 1], dtype=tf.float32, name = 'cues_timeseries')\n",
    "\n",
    "# Visual and audio targets input to the sensory-motor system, represented as just 2D coordinates, one for each, right now\n",
    "input_vis = tf.placeholder(shape=[batch_size, num_timesteps, 2], dtype=tf.float32, name = 'input_vis')\n",
    "input_aud = tf.placeholder(shape=[batch_size, num_timesteps, 2], dtype=tf.float32, name = 'input_aud')\n",
    "\n",
    "loss = 0 # This will accumulate contributions to the loss function\n",
    "outs = [] # Output coordinates from the sensory-motor system\n",
    "rules_chosen = [] # Rules input from the PFC to the sensory-motor system\n",
    "\n",
    "for t in range(num_timesteps): # Iterating over time in the experiment, with batches implicitly being used at each time step\n",
    "    \n",
    "    current_cue = cue_timeseries[:,t] # This is the cue that gets fed into the PFC on this timestep\n",
    "\n",
    "    PFC_state = PFC_step(input_data = current_cue, network_state = PFC_state_previous)\n",
    "    # The output from the PFC into the sensorymotor system gives information about the rule that the sensory-motor system is supposed to execute\n",
    "    with tf.variable_scope(\"PFC_output\", reuse=DO_SHARE):\n",
    "        PFC_output = tf.contrib.layers.fully_connected(PFC_state[0], 1, activation_fn = None) # Note the 1-dimensional rule output; also this layer is linear\n",
    "    rules_chosen.append(PFC_output) # The info sent by PFC to the sensory-motor system, corresponding to the chosen rule\n",
    "\n",
    "    input_rule_to_sensorymotor_system = PFC_output # The rule output from the PFC is sent to the sensory-motor system\n",
    "    input_total = tf.concat([input_vis[:,t], input_aud[:,t], input_rule_to_sensorymotor_system], axis = -1) # Sensory-motor system gets aud, vis & rule inputs\n",
    "    \n",
    "    with tf.variable_scope(\"hidden_sensorymotor\", reuse=DO_SHARE):\n",
    "        hidden_sensorymotor = tf.contrib.layers.fully_connected(input_total, num_hidden_sensorymotor, activation_fn = tf.nn.relu) # Sensory-motor hidden layer\n",
    "    \n",
    "    num_out_sensorymotor = 2 # These are the 2D coordinates that we want to sensory-motor system to produce\n",
    "    \n",
    "    with tf.variable_scope(\"out_sensorymotor\", reuse=DO_SHARE):\n",
    "        out_sensorymotor = tf.contrib.layers.fully_connected(hidden_sensorymotor, num_out_sensorymotor, activation_fn = tf.nn.relu) \n",
    "        # Output coord from sensory-motor system\n",
    "    \n",
    "    outs.append(out_sensorymotor)\n",
    "    \n",
    "    PFC_state_previous = PFC_state[1] # This is needed for the recurrency of the PFC RNN\n",
    "    \n",
    "    for e in range(batch_size): # Here is where we compute a contribution to the loss function for training\n",
    "        cc = current_cue[e][0] # The current cue at this time and this position in the batch\n",
    "        cue_to_rule_mapping_function_output = cue_to_rule_mapping_function(t, cc) # The CORRECT rule to choose in the task\n",
    "        if t>=0: # Always true here but we'll make this change later -- we can use this to set up time-dependent loss functions, e.g., only look at late times\n",
    "            loss_contrib1 = tf.cond(tf.equal(cue_to_rule_mapping_function_output, tf.constant(1, dtype = tf.float32)),\\\n",
    "                                    true_fn = lambda: tf.square(tf.norm(input_vis[e,t] - out_sensorymotor[e])),  false_fn = lambda: 0.0)\n",
    "            loss_contrib2 = tf.cond(tf.equal(cue_to_rule_mapping_function_output, tf.constant(2, dtype = tf.float32)),\\\n",
    "                                    true_fn = lambda: tf.square(tf.norm(input_aud[e,t] - out_sensorymotor[e])),  false_fn = lambda: 0.0)\n",
    "            # The last two lines define the loss function contribution at a given time, \n",
    "            # here the proximity of the output coordinate to the visual input target OR the proximity to the auditory target,\n",
    "            # depending on the correct rule for this moment in the task\n",
    "            loss += (loss_contrib1 + loss_contrib2)\n",
    "            \n",
    "    DO_SHARE = True # This is needed for the recurrency of the RNN, see: https://blog.evjang.com/2016/06/understanding-and-implementing.html\n",
    "\n",
    "# Setting up the session\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_op=optimizer.minimize(loss)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# This is the cue timeseries input provided by the environment\n",
    "# Here random cues are delivered across time and within batch\n",
    "ct = np.reshape([np.random.randint(0,4) for k in range(num_timesteps * batch_size * num_batches)], [num_batches, batch_size, num_timesteps, 1])\n",
    "    \n",
    "# Randomly chosen visual target coordinates\n",
    "in_vis_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_timesteps * batch_size * num_batches)] \n",
    "in_vis_list = np.reshape(in_vis_list_unshaped, [num_batches,batch_size,num_timesteps, 2])\n",
    "\n",
    "# Randomly chosen auditory target coordinates\n",
    "in_aud_list_unshaped = [[np.random.rand(), np.random.rand()] for k in range(num_timesteps * batch_size * num_batches)]\n",
    "in_aud_list = np.reshape(in_aud_list_unshaped, [num_batches,batch_size,num_timesteps, 2])\n",
    "\n",
    "# Running the session and storing the loss function across batches to see the learning curve  \n",
    "losses = []\n",
    "for b in range(num_batches): # Running the training batches\n",
    "    ct_in = ct[b, :, :]\n",
    "    in_v = in_vis_list[b, :, :]\n",
    "    in_a = in_aud_list[b, :, :]\n",
    "    os, l, rc, _ = sess.run([outs, loss, rules_chosen, train_op], feed_dict = {cue_timeseries:ct_in, input_vis: in_v, input_aud:in_a})\n",
    "    # The outputs here are just for the last batch only...\n",
    "    losses.append(l)\n",
    "                \n",
    "# Printing the outputs for visual inspection\n",
    "print \"Loss: %f\" % l\n",
    "print \"\\n\\n\"\n",
    "for q in range(num_timesteps):\n",
    "    print \"timestep %i\" % q\n",
    "    print \"out\", os[q][:], \"\\n\", \"vis in\", in_v[:,q],\"\\n\", \"aud in\", in_a[:, q],\"\\n\",\\\n",
    "    \"rule chosen\", rc[q][:],\"\\n\", \"correct rule\",\\\n",
    "    [sess.run(cue_to_rule_mapping_function(q, float(ct_in[e,q]))) for e in range(batch_size)]  \n",
    "    print \"correctness:\", correctness(q, os, in_a, in_v, ct_in) \n",
    "    print \"\\n\"\n",
    "\n",
    "# Plotting the loss function over time to see the learning process\n",
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.title(\"Loss versus # batches\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
